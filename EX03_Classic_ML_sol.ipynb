{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw50EXgw1iFP"
      },
      "source": [
        "# Задание 1. Bootstrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0lOwk8p1iFP"
      },
      "source": [
        "В этом задании используйте датасет breast_cancer — классический датасет для задачи бинарной классификации. Обучите модели:\n",
        "\n",
        " - `DecisionTreeClassifier`\n",
        " - `RandomForestClassifier`\n",
        " - `LigthGBMClassifier`\n",
        " - `SVC`\n",
        " - `BaggingClassifier` с базовым класификатором `SVC`.\n",
        "\n",
        "Параметры моделей можете оставить по умолчанию или задать сами.\n",
        "\n",
        "Для каждой модели посчитайте [корреляцию Мэтьюса](https://en.wikipedia.org/wiki/Phi_coefficient) — метрику для оценки качества бинарной классификации, в частности, устойчивую к дисбалансу классов, ([`sklearn.metrics.matthews_corrcoef`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html), подробнее почитать про его пользу можно [здесь](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7)) — для предсказанного ею класса и реального.\n",
        "\n",
        "С помощью bootstrap-подхода постройте 90% доверительные интервалы для качества полученных моделей. Используйте функцию `bootstrap_metric()` из лекции.\n",
        "\n",
        "Постройте [боксплоты](https://seaborn.pydata.org/generated/seaborn.boxplot.html) для качества полученных моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjFGF0Yx1iFQ"
      },
      "source": [
        "Импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm1OFGtj1iFQ"
      },
      "outputs": [],
      "source": [
        "import lightgbm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sklearn.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcWzu8701iFQ"
      },
      "source": [
        "Загрузка датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q08Q9iin1iFR"
      },
      "outputs": [],
      "source": [
        "breast_cancer = sklearn.datasets.load_breast_cancer()\n",
        "print(breast_cancer.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh97pBl91iFR"
      },
      "outputs": [],
      "source": [
        "x = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9tmt4Bf1iFR"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "models = {}\n",
        "models[\"rf\"] = RandomForestClassifier(n_estimators=200)\n",
        "models[\"svc\"] = SVC()\n",
        "models[\"dt\"] = DecisionTreeClassifier()\n",
        "models[\"gb\"] = lightgbm.LGBMClassifier(verbose=-1)\n",
        "models[\"bagged svc\"] = BaggingClassifier(estimator=SVC())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyYShyYU1iFR"
      },
      "outputs": [],
      "source": [
        "for name, model in models.items():\n",
        "    print(f\"Fitting {name}\")\n",
        "    model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VMYGcf11iFR"
      },
      "outputs": [],
      "source": [
        "predictions = {}\n",
        "for name, model in models.items():\n",
        "    predictions[name] = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtDFDQAr1iFR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "for name, pred in predictions.items():\n",
        "    qual = matthews_corrcoef(y_pred=pred, y_true=y_test)\n",
        "    print(f\"{name} MCC: {qual:.02f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfZ-_DbT1iFS"
      },
      "outputs": [],
      "source": [
        "def bootstrap_metric(x, y, metric_fn, samples_cnt=1000, alpha=0.05, random_state=42):\n",
        "    size = len(x)\n",
        "\n",
        "    np.random.seed(random_state)\n",
        "    b_metric = np.zeros(samples_cnt)\n",
        "    for it in range(samples_cnt):\n",
        "        poses = np.random.choice(x.shape[0], size=x.shape[0], replace=True)\n",
        "\n",
        "        x_boot = x[poses]\n",
        "        y_boot = y[poses]\n",
        "\n",
        "        m_val = metric_fn(x_boot, y_boot)\n",
        "        b_metric[it] = m_val\n",
        "\n",
        "    return b_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pRQnwEc1iFS"
      },
      "outputs": [],
      "source": [
        "alpha = 0.10\n",
        "boot_mcc = {}\n",
        "for name, pred in predictions.items():\n",
        "    boot = bootstrap_metric(pred, y_test, metric_fn=matthews_corrcoef, samples_cnt=200)\n",
        "    # metric_fn=lambda x, y: matthews_corrcoef(y_pred=x, y_true=y)) - unnecessary code\n",
        "    boot_mcc[name] = boot\n",
        "    print(f\"{name} MCC: \", np.quantile(boot, q=[alpha / 2, 1 - alpha / 2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ace942Un1iFS"
      },
      "outputs": [],
      "source": [
        "mcc_table = pd.DataFrame(boot_mcc)\n",
        "mcc_table = mcc_table.melt(\n",
        "    value_vars=mcc_table.columns, value_name=\"MCC\", var_name=\"model\"\n",
        ")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=mcc_table, x=\"model\", y=\"MCC\")\n",
        "plt.title(\"Models MCC\", size=30)\n",
        "plt.ylabel(\"MCC\", size=25)\n",
        "plt.xticks(size=20)\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK5rcn091iFS"
      },
      "source": [
        "Сделайте вывод о том, какие модели работают лучше.\n",
        "\n",
        "**Напишите вывод**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSl7wruK1iFS"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBiNkxDT1iFS"
      },
      "source": [
        "График с демонстрацией корреляции Мэтьюса для следующих моделей:\n",
        "\n",
        " - `DecisionTreeClassifier`\n",
        " - `RandomForestClassifier`\n",
        " - `LigthGBMClassifier`\n",
        " - `SVC`\n",
        " - `BaggingClassifier` с базовым класификатором `SVC`\n",
        "\n",
        "Пример графика:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw7uBPQf1iFS"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/Exercises/EX03/result_1_task_ex03.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-mMc0w_1iFS"
      },
      "source": [
        "# Задание 2. Дисбаланс классов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdRZ94Ku1iFS"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N-4JzUQ1iFS"
      },
      "outputs": [],
      "source": [
        "!pip install -qU imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xMSFAl31iFS"
      },
      "outputs": [],
      "source": [
        "import imblearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    KFold,\n",
        "    StratifiedKFold,\n",
        "    cross_validate,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5sl-cXz1iFS"
      },
      "source": [
        "Важно обращать внимание на сбалансированность классов в наборе.\n",
        "Предположим, у нас есть некоторый набор данных со следующими метками классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqiF5gMN1iFS"
      },
      "outputs": [],
      "source": [
        "real_labels = [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPBwEZkE1iFT"
      },
      "source": [
        "В наборе 16 объектов относятся к классу 0, а 5 — к классу 1.\n",
        "\n",
        "Мы обучили две модели. Первая всегда выдает 0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxEnAnRY1iFT"
      },
      "outputs": [],
      "source": [
        "model1_res = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNX4c3iz1iFT"
      },
      "source": [
        "Вторая сумела обнаружить некоторую закономерность в признаках:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzXjhIAY1iFT"
      },
      "outputs": [],
      "source": [
        "model2_res = [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24hXHnFq1iFT"
      },
      "source": [
        "Рассчитаем точность Accuracy (см. лекцию 1) для этих моделей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycY-Asyx1iFT"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy for model1: \", accuracy_score(real_labels, model1_res))\n",
        "print(\"Accuracy for model2: \", accuracy_score(real_labels, model2_res))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s03cG5n81iFT"
      },
      "source": [
        "Accuracy нельзя использовать, если данные не сбалансированы. Для несбалансированных данных необходимо использовать свои метрики и модели. Одной из таких метрик является balanced accuracy. При вычислении данной метрики считается полнота (recall) отдельно для каждого класса и вычисляется среднее значение:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc-23Fkf1iFT"
      },
      "outputs": [],
      "source": [
        "# Balanced accuracy for model1 = (16/16+0/5)/2 = 0.5\n",
        "print(\n",
        "    \"Balanced accuracy for model1: \", balanced_accuracy_score(real_labels, model1_res)\n",
        ")\n",
        "# Balanced accuracy for model2 = (12/16+4/5)/2 = 0.775\n",
        "print(\n",
        "    \"Balanced accuracy for model2: \", balanced_accuracy_score(real_labels, model2_res)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbMPJeHO1iFT"
      },
      "source": [
        "**Всегда проверяйте**, являются ли ваши данные сбалансированными и могут ли выбранные для оценки модели метрики работать с несбалансированными классами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnDr_pQP1iFT"
      },
      "source": [
        "Загрузим датасет с различными биомаркерами пациентов с меланомой (обезличенный, информации о пациентах нет) и переменной, содержащей 1, если пациент ответил на иммунотерапию (терапия помогла пациенту и произошло уменьшение размеров опухоли), и 0, если не ответил. Количество пациентов, отвечающих на терапию, сильно меньше пациентов, которым терапия не помогает, поэтому предсказание ответа пациента на терапию на основании биомаркеров — актуальная задача в онкологии. В данном задании вам предстоит попробовать её решить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lthAv-DR1iFT"
      },
      "outputs": [],
      "source": [
        "cancer = pd.read_table(\n",
        "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/Cancer_dataset_2.tsv\",\n",
        "    index_col=\"sample_id\",\n",
        ")\n",
        "display(cancer.head())\n",
        "\n",
        "# split the data on features (x) and dependant variable (y)\n",
        "y = cancer[\"Response\"]\n",
        "x = cancer.drop(\"Response\", axis=1)\n",
        "print(\"\\nNumber of patients responded to immunotherapy:\")\n",
        "display(y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa6RcuxT1iFT"
      },
      "source": [
        "В данном случае имеет место несбалансированность классов в наборе данных: пациентов, ответивших на терапию, гораздо меньше.\n",
        "\n",
        "Есть два способа работы с несбалансированными по классам данными. Первый способ &mdash; это получение стратифицированных выборок. Необходимо иметь одинаковую долю образцов каждого класса в тренировочной и тестовой выборках, иначе возникает риск получения смещённых выборок, что приводит к некорректной оценке качества модели. Второй способ &mdash; это использование специальных алгоритмов, учитывающих несбалансированность классов.\n",
        "\n",
        "\n",
        "В данном задании вам нужно продемонстрировать эффективность различных подходов  работы с несбалансированными выборками. Для этого вы будете использовать три модели, представленные ниже:\n",
        "\n",
        "1. [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), библиотека sklearn\n",
        "2. [`RandomForestClassifier` с балансировкой классов](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), библиотека sklearn — меняет стандартный вес каждого класса, равный 1, на долю класса во входных данных (см. `class_weight`).\n",
        "3. [`BalancedRandomForestClassifier`](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedRandomForestClassifier.html), библиотека imblearn — сэмплирует псевдовыборки таким образом, что в каждой псевдовыборке, которая подается на вход модели, баланс классов оказывается \"выправлен\".\n",
        "\n",
        "Оцените эффективность подходов с помощью кросс-валидации, производя разбиение с учетом репрезентации классов и без него. В качестве метрики, отображающей эффективность модели, используйте значения `accuracy` и `balanced_accuracy`. Проинтерпретируйте результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vx8QM0J1iFT"
      },
      "outputs": [],
      "source": [
        "?imblearn.ensemble.BalancedRandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfbYTEL91iFX"
      },
      "outputs": [],
      "source": [
        "?cross_validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHNWE7y11iFX"
      },
      "source": [
        "Объекты, принадлежащие разным классам, распределены неравномерно. Для адекватной работы `cross_validate` нужно перемешать данные. Для этого используйте флаг `shuffle=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElYld24m1iFX"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "rng = np.random.RandomState(42)\n",
        "\n",
        "cvs = {\n",
        "    \"cv_rand\": KFold(n_splits=3, shuffle=True, random_state=rng),\n",
        "    \"sv_strat\": StratifiedKFold(n_splits=3, shuffle=True, random_state=rng),\n",
        "}\n",
        "\n",
        "models = {\n",
        "    \"rf_sklearn\": RandomForestClassifier(\n",
        "        n_estimators=500, max_depth=10, random_state=rng\n",
        "    ),\n",
        "    \"rf_sklearn_balanced\": RandomForestClassifier(\n",
        "        n_estimators=500, max_depth=10, class_weight=\"balanced\", random_state=rng\n",
        "    ),\n",
        "    \"rf_imblearn\": imblearn.ensemble.BalancedRandomForestClassifier(\n",
        "        n_estimators=500, max_depth=10, random_state=rng\n",
        "    ),\n",
        "}\n",
        "\n",
        "for name_model, model in models.items():\n",
        "    for name_cv, cv in cvs.items():\n",
        "        scores = cross_validate(\n",
        "            model, X=x, y=y, scoring=(\"accuracy\", \"balanced_accuracy\"), cv=cv, n_jobs=-1\n",
        "        )\n",
        "        print(\n",
        "            f'{name_model} {name_cv}: accuracy = {scores[\"test_accuracy\"].mean()}, balanced_accuracy = {scores[\"test_balanced_accuracy\"].mean()}'\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjJwu1ye1iFX"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=3, shuffle=True, random_state=rng)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=500, max_depth=10)\n",
        "scores = cross_validate(\n",
        "    model, X=x, y=y, scoring=(\"accuracy\", \"balanced_accuracy\"), cv=cv, n_jobs=-1\n",
        ")\n",
        "\n",
        "for name_model, model in models.items():\n",
        "    for name_cv, cv in cvs.items():\n",
        "        scores = cross_validate(\n",
        "            model, X=x, y=y, scoring=(\"accuracy\", \"balanced_accuracy\"), cv=cv, n_jobs=-1\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTQwEaIX1iFX"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, random_state=42, test_size=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEXsCDgU1iFY"
      },
      "outputs": [],
      "source": [
        "def bootstrap_metric(x, y, metric_fn, samples_cnt=1000, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    b_metric = np.zeros(samples_cnt)\n",
        "    for it in range(samples_cnt):\n",
        "        poses = np.random.choice(x.shape[0], size=x.shape[0], replace=True)\n",
        "\n",
        "        x_boot = x[poses]\n",
        "        y_boot = y[poses]\n",
        "        m_val = metric_fn(x_boot, y_boot)\n",
        "        b_metric[it] = m_val\n",
        "\n",
        "    return b_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTFAcdZR1iFY"
      },
      "outputs": [],
      "source": [
        "alpha = 0.1\n",
        "boot = {}\n",
        "models = {\n",
        "    \"rf_sklearn\": RandomForestClassifier(\n",
        "        n_estimators=500, max_depth=10, random_state=42\n",
        "    ),\n",
        "    \"rf_sklearn_balanced\": RandomForestClassifier(\n",
        "        n_estimators=500, max_depth=10, class_weight=\"balanced\", random_state=42\n",
        "    ),\n",
        "    \"rf_imblearn\": imblearn.ensemble.BalancedRandomForestClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=10,\n",
        "        random_state=42,\n",
        "        sampling_strategy=\"all\",\n",
        "        replacement=True,\n",
        "    ),\n",
        "}\n",
        "\n",
        "for name_model, model in models.items():\n",
        "    model.fit(x_train, y_train)\n",
        "    pred = model.predict(x_test)\n",
        "    boot[name_model] = bootstrap_metric(\n",
        "        pred, y_test, metric_fn=lambda x, y: balanced_accuracy_score(y_true=y, y_pred=x)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aabAW9Pi1iFY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "sns.boxplot(\n",
        "    y=np.concatenate(\n",
        "        [boot[\"rf_sklearn\"], boot[\"rf_sklearn_balanced\"], boot[\"rf_imblearn\"]]\n",
        "    ),\n",
        "    x=[\"rf_sklearn\"] * 1000 + [\"rf_sklearn_balanced\"] * 1000 + [\"rf_imblearn\"] * 1000,\n",
        ")\n",
        "plt.ylabel(\"Balanced accuracy\", size=20)\n",
        "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLac8RVS1iFY"
      },
      "source": [
        "Какая модель лучше справляется с дисбалансом классов?\n",
        "\n",
        "**Напишите вывод**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKQ1wC381iFY"
      },
      "source": [
        "Выводы:\n",
        "1. Оценка качества модели на стратифицированной выборке более адекватна, что можно заметить по росту balanced_accuracy для моделей, обученных и протестированных на стратифицированной выборке\n",
        "2. Модели, учитывающие дисбаланс классов, лучше справляются с задачей классификации при наличии дисбаланса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMwajqJq1iFY"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liBIpuUD1iFY"
      },
      "source": [
        "Получить значения `accuracy` и `balanced_accuracy`для моделей:\n",
        "1. `RandomForestClassifier`, библиотека sklearn;\n",
        "2. `RandomForestClassifier с балансировкой классов`, библиотека sklearn;\n",
        "3. `BalancedRandomForestClassifier`, библиотека imblearn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBmK56EI1iFY"
      },
      "source": [
        "# Задание 3. Разные типы бустингов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6lWGySn1iFY"
      },
      "source": [
        "В этом задании будем использовать датасет с рейтингом блюд по некоторым характеристикам.\n",
        "\n",
        "В некоторых реализациях градиентного бустинга есть возможность использовать другой метод обучения. Например, в XGB есть тип `dart`, а в lgbm — `goss`. Это позволяет составлять более эффективные ансамбли.\n",
        "\n",
        "Используя кросс-валидацию (используйте 3 фолда), обучите модели:\n",
        "* CatboostRegressor\n",
        "* XGBRegressor\n",
        "* LGBMRegressor\n",
        "\n",
        "Сохраните модель на каждом фолде и посчитайте `mse` для тестовой выборки, используя модель с каждого фолда. Получите предсказания всех 9 моделей на тестовой выборке и усредните их. Затем посчитайте `mse` для усредненных предсказаний.\n",
        "\n",
        "Напишите выводы о полученном качестве моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaR8shbF1iFY"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3_70_Ji1iFY"
      },
      "outputs": [],
      "source": [
        "!pip install -q catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljyNAuYY1iFY"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "import catboost\n",
        "import lightgbm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55cpR1hq1iFY"
      },
      "source": [
        "Загрузка датасета:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_b-hKAS1iFY"
      },
      "outputs": [],
      "source": [
        "recipies = pd.read_csv(\n",
        "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/recipes.csv\"\n",
        ")\n",
        "recipies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhZ0w80I1iFZ"
      },
      "outputs": [],
      "source": [
        "y = recipies[\"rating\"]\n",
        "x = recipies.drop([\"rating\"], axis=1)\n",
        "\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    x.values, y.values, train_size=0.7, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG9M7lhr1iFZ"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for num_fold, (train_index, val_index) in enumerate(kf.split(x)):\n",
        "    x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    model = catboost.CatBoostRegressor(\n",
        "        iterations=500,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42,\n",
        "        verbose=0,\n",
        "    )\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    models[f\"Catboost_{num_fold+1}\"] = model\n",
        "\n",
        "cb_test_pred = np.mean(\n",
        "    [\n",
        "        models[\"Catboost_1\"].predict(x_test),\n",
        "        models[\"Catboost_2\"].predict(x_test),\n",
        "        models[\"Catboost_3\"].predict(x_test),\n",
        "    ],\n",
        "    axis=0,\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Catboost 1 fold mse score: \", mse(y_test, models[\"Catboost_1\"].predict(x_test)))\n",
        "print(\"Catboost 2 fold mse score: \", mse(y_test, models[\"Catboost_2\"].predict(x_test)))\n",
        "print(\"Catboost 3 fold mse score: \", mse(y_test, models[\"Catboost_3\"].predict(x_test)))\n",
        "print(\"Catboost all folds mean mse score: \", mse(y_test, cb_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mpXwzmg1iFZ"
      },
      "outputs": [],
      "source": [
        "for num_fold, (train_index, val_index) in enumerate(kf.split(x)):\n",
        "    x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    model = xgboost.XGBRegressor(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42,\n",
        "        min_child_weight=9,\n",
        "        n_jobs=-1,\n",
        "        objective=\"reg:squarederror\",\n",
        "        booster=\"dart\",\n",
        "        rate_drop=0.1,\n",
        "        one_drop=1,\n",
        "        verbosity=0,\n",
        "    )\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    models[f\"xgb_{num_fold+1}\"] = model\n",
        "\n",
        "xgb_test_pred = np.mean(\n",
        "    [\n",
        "        models[\"xgb_1\"].predict(x_test),\n",
        "        models[\"xgb_2\"].predict(x_test),\n",
        "        models[\"xgb_3\"].predict(x_test),\n",
        "    ],\n",
        "    axis=0,\n",
        ")\n",
        "\n",
        "\n",
        "print(\"xgb 1 fold mse score: \", mse(y_test, models[\"xgb_1\"].predict(x_test)))\n",
        "print(\"xgb 2 fold mse score: \", mse(y_test, models[\"xgb_2\"].predict(x_test)))\n",
        "print(\"xgb 3 fold mse score: \", mse(y_test, models[\"xgb_3\"].predict(x_test)))\n",
        "print(\"xgb all folds mean mse score: \", mse(y_test, xgb_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fzU8rgS1iFZ"
      },
      "outputs": [],
      "source": [
        "for num_fold, (train_index, val_index) in enumerate(kf.split(x)):\n",
        "    x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    model = lightgbm.LGBMRegressor(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=-1,\n",
        "        num_leaves=2**5,\n",
        "        random_state=42,\n",
        "        min_child_weight=9,\n",
        "        n_jobs=-1,\n",
        "        boosting_type=\"goss\",\n",
        "        verbose=-1,\n",
        "    )\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    models[f\"lgbm_{num_fold+1}\"] = model\n",
        "\n",
        "lgbm_test_pred = np.mean(\n",
        "    [\n",
        "        models[\"lgbm_1\"].predict(x_test),\n",
        "        models[\"lgbm_2\"].predict(x_test),\n",
        "        models[\"lgbm_3\"].predict(x_test),\n",
        "    ],\n",
        "    axis=0,\n",
        ")\n",
        "\n",
        "\n",
        "print(\"lgbm 1 fold mse score: \", mse(y_test, models[\"lgbm_1\"].predict(x_test)))\n",
        "print(\"lgbm 2 fold mse score: \", mse(y_test, models[\"lgbm_2\"].predict(x_test)))\n",
        "print(\"lgbm 3 fold mse score: \", mse(y_test, models[\"lgbm_3\"].predict(x_test)))\n",
        "print(\"lgbm all folds mean mse score: \", mse(y_test, lgbm_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDMTvVtG1iFZ"
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "for model in models:\n",
        "    print(model)\n",
        "    all_preds.append(models[model].predict(x_test))\n",
        "\n",
        "print(\"ensemble mse: \", mse(y_test, np.mean(all_preds, axis=0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On2bjhqb1iFZ"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez_l-eoJ1iFZ"
      },
      "source": [
        "Получить значения MSE для всех моделей и значение MSE, усреднив предсказания всех моделей. Написать вывод.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNs41GtU1iFZ"
      },
      "source": [
        "# Задание 4. Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YchD35bh1iFZ"
      },
      "source": [
        "В этом задании нужно подобрать параметры для бустинга `CatBoostRegressor`, используя библиотеку `optuna`. И улучшить результат по сравнению со стандартными параметрами.\n",
        "\n",
        "Список параметров для подбора:\n",
        "\n",
        "* `depth`\n",
        "* `iterations`\n",
        "* `learning_rate`\n",
        "* `colsample_bylevel`\n",
        "* `subsample`\n",
        "* `l2_leaf_reg`\n",
        "* `min_data_in_leaf`\n",
        "* `max_bin`\n",
        "* `random_strength`\n",
        "* `bootstrap_type`\n",
        "\n",
        "**Важно!** *Подбирать параметры нужно на валидационной выборке*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxBaAn0F1iFZ"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx9diQWV1iFZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q catboost\n",
        "!pip install -q optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y962T2Bz1iFZ"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from catboost import CatBoostRegressor\n",
        "from optuna.samplers import RandomSampler\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWjSR2Sa1iFZ"
      },
      "source": [
        "Загрузка датасета:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOg222Sj1iFZ"
      },
      "outputs": [],
      "source": [
        "recipies = pd.read_csv(\n",
        "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/recipes.csv\"\n",
        ")\n",
        "recipies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jserDBVu1iFZ"
      },
      "outputs": [],
      "source": [
        "y = recipies[\"rating\"]\n",
        "x = recipies.drop([\"rating\"], axis=1)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x.values, y.values, train_size=0.7, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlAjM18N1iFa"
      },
      "outputs": [],
      "source": [
        "model = CatBoostRegressor(random_seed=42)\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    eval_set=(x_test, y_test),\n",
        "    verbose=200,\n",
        "    use_best_model=True,\n",
        "    plot=False,\n",
        "    early_stopping_rounds=100,\n",
        ")\n",
        "\n",
        "print(\"\\nmse_score before tuning: \", mse(y_test, model.predict(x_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3N2unnE1iFa"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    models = {}\n",
        "    params = {\n",
        "        \"depth\": trial.suggest_int(\"depth\", 4, 12),\n",
        "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
        "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\", 1, 10),\n",
        "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 5),\n",
        "        \"max_bin\": trial.suggest_int(\"max_bin\", 32, 256),\n",
        "        \"random_strength\": trial.suggest_float(\"random_strength\", 0, 2),\n",
        "        \"bootstrap_type\": trial.suggest_categorical(\n",
        "            \"bootstrap_type\", [\"Bernoulli\", \"MVS\"]\n",
        "        ),\n",
        "        \"task_type\": \"CPU\",\n",
        "        \"thread_count\": -1,\n",
        "        \"random_seed\": 42,\n",
        "        \"early_stopping_rounds\": 50,\n",
        "    }\n",
        "\n",
        "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    for num_fold, (train_index, val_index) in enumerate(kf.split(x_train_all)):\n",
        "        x_train, x_val = x_train_all[train_index], x_train_all[val_index]\n",
        "        y_train, y_val = y_train_all[train_index], y_train_all[val_index]\n",
        "\n",
        "        model = CatBoostRegressor(**params)\n",
        "\n",
        "        model.fit(\n",
        "            x_train,\n",
        "            y_train,\n",
        "            eval_set=(x_val, y_val),\n",
        "            verbose=0,\n",
        "            use_best_model=True,\n",
        "            plot=False,\n",
        "        )\n",
        "\n",
        "        models[f\"Catboost_{num_fold+1}\"] = model\n",
        "\n",
        "    cb_test_pred = np.mean(\n",
        "        [\n",
        "            models[\"Catboost_1\"].predict(x_val),\n",
        "            models[\"Catboost_2\"].predict(x_val),\n",
        "            models[\"Catboost_3\"].predict(x_val),\n",
        "        ],\n",
        "        axis=0,\n",
        "    )\n",
        "    result_score = mse(y_val, cb_test_pred)\n",
        "\n",
        "    return result_score\n",
        "\n",
        "\n",
        "# Create \"exploration\"\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\", study_name=\"Optimizer\", sampler=RandomSampler(42)\n",
        ")\n",
        "\n",
        "study.optimize(\n",
        "    objective, n_trials=100\n",
        ")  # The more iterations, the higher the chances of catching the most optimal hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T6NMH6j1iFa"
      },
      "outputs": [],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkloA8f51iFa"
      },
      "outputs": [],
      "source": [
        "model = CatBoostRegressor(**study.best_params, random_seed=42)\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    eval_set=(x_test, y_test),\n",
        "    verbose=200,\n",
        "    use_best_model=True,\n",
        "    plot=False,\n",
        "    early_stopping_rounds=100,\n",
        ")\n",
        "\n",
        "print(\"\\nmse_score after tuning: \", mse(y_test, model.predict(x_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62UrWsWQ1iFa"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsa4GBen1iFa"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "Значение `mse` с подобранными параметрами меньше, чем при стандартных параметрах."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}