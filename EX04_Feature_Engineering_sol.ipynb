{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELFSV30c2h92"
      },
      "source": [
        "# Задание 1. Методы понижения размерности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA7nzLnJ2h93"
      },
      "source": [
        "Примените методы понижения размерности: PCA, t-SNE и UMAP к изображениям клеток крови из датасета BloodMNIST. Отобразите проекцию данных на двумерное пространство, так как это допускает наиболее простую визуализацию полученного результата (воспользуйтесь [`sns.scatterplot`](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)).  Какой метод позволяет лучше разделить данные в пространстве? Опишите ваши наблюдения.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHFSmVXb2h93"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "Пример графика для одного из пунктов задания:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/Exercises/EX04/result_1_task_ex04.png\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAiDhPtZ2h93"
      },
      "source": [
        "Установка и импорт необходимых библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFxjgPmM2h93"
      },
      "outputs": [],
      "source": [
        "!pip install -q umap-learn\n",
        "!pip install -q --upgrade scikit-image\n",
        "!pip install -q --upgrade git+https://github.com/MedMNIST/MedMNIST.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4k8vpco2h94"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "import medmnist\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from medmnist import INFO\n",
        "from sklearn import manifold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "matplotlib.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-21UmBMM2h94"
      },
      "source": [
        "Произведем загрузку данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdyUdzus2h94"
      },
      "outputs": [],
      "source": [
        "data_flag = \"bloodmnist\"\n",
        "download = True\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info[\"task\"]\n",
        "n_channels = info[\"n_channels\"]\n",
        "n_classes = len(info[\"label\"])\n",
        "\n",
        "DataClass = getattr(medmnist, info[\"python_class\"])\n",
        "\n",
        "\n",
        "# load the data\n",
        "bloodmnist = DataClass(split=\"train\", download=download)\n",
        "print(bloodmnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-KShi2X2h95"
      },
      "source": [
        "Доступ к данным идет посредством обращения к ключу `bloodmnist.imgs`, доступ к разметке классов — через `bloodmnist.labels`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpOxm5yi2h95"
      },
      "outputs": [],
      "source": [
        "x = bloodmnist.imgs / 255.0\n",
        "x = x.reshape(-1, 2352)\n",
        "y = pd.Series(bloodmnist.labels.reshape(-1))\n",
        "y = y.astype(\"int\").map(dict(zip(range(0, 8), info[\"label\"].values())))\n",
        "\n",
        "\n",
        "bloodmnist.montage(length=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS_A5gDm2h95"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwPe7MNG2h95"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "pca = PCA(n_components=2)\n",
        "x_pca = pca.fit_transform(x_scaled)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.scatterplot(\n",
        "    x=x_pca[:, 0],\n",
        "    y=x_pca[:, 1],\n",
        "    hue=y,\n",
        "    palette=sns.color_palette(\"hls\", 8),\n",
        "    legend=\"full\",\n",
        "    alpha=0.5,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeY1LCdK2h95"
      },
      "source": [
        "## t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N8dmhT72h95"
      },
      "outputs": [],
      "source": [
        "tsne = manifold.TSNE(n_components=2, random_state=42)\n",
        "x_tsne = tsne.fit_transform(x)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.scatterplot(\n",
        "    x=x_tsne[:, 0],\n",
        "    y=x_tsne[:, 1],\n",
        "    hue=y,\n",
        "    palette=sns.color_palette(\"hls\", 8),\n",
        "    legend=\"full\",\n",
        "    alpha=0.5,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIV6sM_w2h95"
      },
      "source": [
        "## UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ2zv4rv2h96"
      },
      "outputs": [],
      "source": [
        "UMAP = umap.UMAP(n_components=2, n_neighbors=100)\n",
        "x_umap = UMAP.fit_transform(x)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.scatterplot(\n",
        "    x=x_umap[:, 0],\n",
        "    y=x_umap[:, 1],\n",
        "    hue=y,\n",
        "    palette=sns.color_palette(\"hls\", 8),\n",
        "    legend=\"full\",\n",
        "    alpha=0.5,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc1qm0vK2h96"
      },
      "source": [
        "Выводы:\n",
        "\n",
        "*Ваш текст тут*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HbQE8F82h96"
      },
      "source": [
        "# Задание 2. Использование понижения размерности для ускорения обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJTzJwGX2h96"
      },
      "source": [
        "Рассмотрите набор данных TissueMNIST. В этом задании вам нужно сравнить производительность двух моделей: обученной с использованием всех доступных признаков и обученной на данных пониженной размерности. От вас требуется:\n",
        "\n",
        "1. Построить модель `RandomForestClassifier()` и обучить ее на тренировочной выборке, оценить `accuracy` модели на тестовой выборке и время, потраченное на обучение.\n",
        "2. Построить модель PCA на тренировочных данных и определить число главных компонент, объясняющих 90% дисперсии (или используйте любой другой способ выбора оптимального числа главных компонент, разбиравшийся на лекции).\n",
        "3. Преобразовать данные тестовой выборки на главные компоненты полученной модели PCA.\n",
        "4. Построить модель `RandomForestClassifier()` и обучить ее на данных пониженной размерности, оценить `accuracy` модели на тестовой выборке и время, потраченное на обучение.\n",
        "5. Описать ваши наблюдения, сделать выводы.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q0ETF7o2h96"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "Получить значения точности (`accuracy`) и времени обучения `RandomForestClassifier()` на обычных данных и данных с пониженной размерностью."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zFLoMuk2h96"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSzaqAop2h96"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade git+https://github.com/MedMNIST/MedMNIST.git\n",
        "!pip install -q --upgrade scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP0z-bpB2h96"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import medmnist\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from medmnist import INFO\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "matplotlib.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFuF-BTX2h96"
      },
      "source": [
        "Произведем загрузку данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCFWuFpB2h96"
      },
      "outputs": [],
      "source": [
        "data_flag = \"tissuemnist\"\n",
        "download = True\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info[\"task\"]\n",
        "n_channels = info[\"n_channels\"]\n",
        "n_classes = len(info[\"label\"])\n",
        "\n",
        "DataClass = getattr(medmnist, info[\"python_class\"])\n",
        "\n",
        "# load the data\n",
        "tissuemnist = DataClass(split=\"test\", download=download)\n",
        "print(tissuemnist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77CWmZcE2h97"
      },
      "outputs": [],
      "source": [
        "x = tissuemnist.imgs / 255.0\n",
        "x = x.reshape(-1, 784)\n",
        "y = tissuemnist.labels\n",
        "\n",
        "tissuemnist.montage(length=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aex3zR2l2h97"
      },
      "outputs": [],
      "source": [
        "rng = np.random.RandomState(42)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=rng)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "# Your code here\n",
        "t0 = time.time()\n",
        "rf.fit(x_train, y_train.ravel())\n",
        "y_pred = rf.predict(x_test)\n",
        "rf_scores = accuracy_score(y_test, y_pred)\n",
        "t1 = time.time()\n",
        "rf_time = t1 - t0\n",
        "\n",
        "print(f\"Test accuracy: {rf_scores:0.3f}\")\n",
        "print(f\"Training time: {rf_time:0.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMdEq0Tc2h97"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "x_pca_train = pca.fit_transform(x_train_scaled)\n",
        "x_pca_test = pca.transform(x_test_scaled)\n",
        "print(f\"n components explaining 90% of variance: {pca.n_components_}\")\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=x_pca_train[:, 0],\n",
        "    y=x_pca_train[:, 1],\n",
        "    hue=y_train[:, 0],\n",
        "    palette=sns.color_palette(\"hls\", 8),\n",
        "    legend=\"full\",\n",
        "    alpha=0.5,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTH6k6SV2h97"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "rf_pca = RandomForestClassifier(n_estimators=200, random_state=rng)\n",
        "t0 = time.time()\n",
        "rf_pca.fit(x_pca_train, y_train.ravel())\n",
        "y_pred = rf_pca.predict(x_pca_test)\n",
        "pca_scores = accuracy_score(y_test, y_pred)\n",
        "t1 = time.time()\n",
        "pca_time = t1 - t0\n",
        "\n",
        "print(f\"Test accuracy: {pca_scores:0.3f}\")\n",
        "print(f\"Training time: {pca_time:0.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_WG-j3u2h97"
      },
      "outputs": [],
      "source": [
        "print(f\"Diff time: {(rf_time-pca_time):0.3f}\")\n",
        "print(f\"Diff accuracy {(rf_scores-pca_scores):0.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj3Eo2jd2h97"
      },
      "source": [
        "# Задание 3. Отбор признаков\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94EttUx2h97"
      },
      "source": [
        "У нас есть датасет из 30 признаков. Известно, что для улучшения качества предсказания достаточно использовать 5 признаков, но неизвестно, какие.\n",
        "\n",
        "Отберите 5 признаков, используя методы отбора признаков, и увеличьте качество предсказания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiyEK2U02h97"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "* Accuracy модели > 0.62.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEuqiD3e2h97"
      },
      "source": [
        "Импорт и установка необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4svwRM1B2h97"
      },
      "outputs": [],
      "source": [
        "!pip install -q catboost phik boruta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOKdyqXu2h97"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "matplotlib.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yRQudBi2h-A"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/feature_select_ex.csv\"\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLA0UWd02h-A"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    df.drop(columns=[\"target\"]), df[\"target\"], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred_rf = rf.predict(x_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Use all features, accuracy: {accuracy_rf:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLKtB9X12h-A"
      },
      "outputs": [],
      "source": [
        "import phik\n",
        "\n",
        "df_result = pd.DataFrame()\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "phik_overview = df.phik_matrix().round(2).sort_values(\"target\")\n",
        "# mask = np.triu(np.ones_like(df_new, dtype=bool))\n",
        "\n",
        "\n",
        "sotred_columns = (\n",
        "    df.phik_matrix(interval_cols=df.columns)\n",
        "    .round(2)\n",
        "    .sort_values(\"target\", ascending=False, axis=1)\n",
        "    .columns\n",
        ")\n",
        "\n",
        "phik_result = (\n",
        "    df.phik_matrix(interval_cols=df.columns)\n",
        "    .round(2)\n",
        "    .sort_values(\"target\", ascending=False, axis=1)\n",
        "    .reindex(sotred_columns)\n",
        ")\n",
        "\n",
        "heatmap = sns.heatmap(\n",
        "    phik_result,\n",
        "    annot=True,\n",
        "    square=True,\n",
        "    cmap=\"Blues\",\n",
        "    cbar_kws={\"fraction\": 0.01},  # shrink colour bar\n",
        "    linewidth=2,\n",
        "    # mask=mask\n",
        ")\n",
        "\n",
        "heatmap.set_xticklabels(\n",
        "    heatmap.get_xticklabels(), rotation=45, horizontalalignment=\"right\"\n",
        ")\n",
        "heatmap.set_title(\"Correalation heatmap\", fontdict={\"fontsize\": 18}, pad=16)\n",
        "plt.show()\n",
        "df_result[\"phik\"] = phik_result.index[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO1AFJwU2h-B"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(x_train_scaled, y_train)\n",
        "\n",
        "temp_df = pd.DataFrame({\"name\": x_train.columns, \"coef\": lr.coef_[0]}).sort_values(\n",
        "    \"coef\", key=abs, ascending=False\n",
        ")\n",
        "\n",
        "temp_df[\"sign\"] = [\"neg\" if x < 0 else \"pos\" for x in temp_df[\"coef\"]]\n",
        "\n",
        "palette = {\"neg\": sns.xkcd_rgb[\"orange\"], \"pos\": sns.xkcd_rgb[\"azure\"]}\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.barplot(\n",
        "    data=temp_df,\n",
        "    y=\"name\",\n",
        "    x=\"coef\",\n",
        "    hue=\"sign\",\n",
        "    palette=palette,\n",
        "    legend=False,\n",
        "    orient=\"h\",\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "df_result[\"logreg_coef\"] = temp_df[\"name\"].reset_index()[\"name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjYoha0Z2h-B"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "rf_selector = SelectFromModel(rf)\n",
        "rf_selector.fit(x_train, y_train)  # Fit it on the training data\n",
        "\n",
        "temp_df = pd.DataFrame(\n",
        "    {\"name\": x_train.columns, \"coef\": rf_selector.estimator_.feature_importances_}\n",
        ").sort_values(\"coef\", key=abs, ascending=False)\n",
        "\n",
        "temp_df[\"sign\"] = [\"neg\" if x < 0 else \"pos\" for x in temp_df[\"coef\"]]\n",
        "\n",
        "palette = {\"neg\": sns.xkcd_rgb[\"orange\"], \"pos\": sns.xkcd_rgb[\"azure\"]}\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.barplot(\n",
        "    data=temp_df,\n",
        "    y=\"name\",\n",
        "    x=\"coef\",\n",
        "    hue=\"sign\",\n",
        "    palette=palette,\n",
        "    legend=False,\n",
        "    orient=\"h\",\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "df_result[\"rf_fi\"] = temp_df[\"name\"].reset_index()[\"name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVdexAT_2h-B"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "model = CatBoostClassifier(random_state=42, thread_count=-1)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    eval_set=(x_test, y_test),\n",
        "    verbose=100,\n",
        "    plot=False,\n",
        "    early_stopping_rounds=100,\n",
        ")\n",
        "\n",
        "temp_df = pd.DataFrame(\n",
        "    {\"name\": x_train.columns, \"coef\": model.feature_importances_}\n",
        ").sort_values(\"coef\", key=abs, ascending=False)\n",
        "\n",
        "\n",
        "temp_df[\"sign\"] = [\"neg\" if x < 0 else \"pos\" for x in temp_df[\"coef\"]]\n",
        "\n",
        "palette = {\"neg\": sns.xkcd_rgb[\"orange\"], \"pos\": sns.xkcd_rgb[\"azure\"]}\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.barplot(\n",
        "    data=temp_df,\n",
        "    y=\"name\",\n",
        "    x=\"coef\",\n",
        "    hue=\"sign\",\n",
        "    palette=palette,\n",
        "    legend=False,\n",
        "    orient=\"h\",\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "df_result[\"catboost_fi\"] = temp_df[\"name\"].reset_index()[\"name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qufzfkDy2h-B"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(x_train, y_train)\n",
        "perm_importance = permutation_importance(\n",
        "    rf, x_train, y_train, n_repeats=10, random_state=42\n",
        ")\n",
        "\n",
        "temp_df = pd.DataFrame(\n",
        "    {\"name\": x_train.columns, \"imp\": perm_importance.importances_mean}\n",
        ").sort_values(\"imp\", ascending=False)\n",
        "df_result[\"rf_pi\"] = temp_df[\"name\"].reset_index()[\"name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38IccSeO2h-B"
      },
      "outputs": [],
      "source": [
        "from boruta import BorutaPy\n",
        "\n",
        "# define Boruta feature selection method\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "feat_selector = BorutaPy(model, n_estimators=100, verbose=0, random_state=42)\n",
        "\n",
        "# find all relevant features\n",
        "feat_selector.fit(x_train.values, y_train.values)\n",
        "feature_ranks = list(\n",
        "    zip(x_train.columns, feat_selector.ranking_, feat_selector.support_)\n",
        ")\n",
        "\n",
        "temp_df = pd.DataFrame(feature_ranks, columns=[\"feature\", \"rank\", \"boruta_keep\"])\n",
        "temp_df.sort_values(\"rank\")\n",
        "\n",
        "df_result[\"rf_boruta\"] = temp_df.sort_values(\"rank\")[\"feature\"].reset_index()[\"feature\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66o2mVch2h-B"
      },
      "outputs": [],
      "source": [
        "stacked = df_result.stack().value_counts()\n",
        "top_features = stacked.index[:5]\n",
        "\n",
        "print(f\"Top 5 selected features:\\n{list(top_features)}\")\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(x_train[top_features], y_train)\n",
        "y_pred_rf = rf.predict(x_test[top_features])\n",
        "fs_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"\\nUse top 5 selected features, accuracy: {fs_accuracy_rf:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJZEjrw62h-B"
      },
      "outputs": [],
      "source": [
        "from mlxtend.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "sffs = SequentialFeatureSelector(\n",
        "    RandomForestClassifier(random_state=42),  # represents the classifier\n",
        "    k_features=5,  # the number of features you want to select\n",
        "    forward=True,  # add features\n",
        "    floating=True,  # remove features\n",
        "    scoring=\"accuracy\",  # means that the selection will be decided by the accuracy of the classifier.\n",
        "    cv=KFold(n_splits=3, shuffle=True, random_state=42),\n",
        ")\n",
        "\n",
        "sffs.fit(x_train.values, y_train)  # performs the actual SFFS algorithm\n",
        "temp_df = pd.DataFrame.from_dict(sffs.get_metric_dict()).T\n",
        "temp_df.head(temp_df.shape[0])\n",
        "sffs_columns = [\n",
        "    \"feature_\" + str(int(i) + 1) for i in sffs.get_metric_dict()[5][\"feature_names\"]\n",
        "]\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(x_train[sffs_columns], y_train)\n",
        "y_pred_rf = rf.predict(x_test[sffs_columns])\n",
        "sffs_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Use top 5 sffs selected features, accuracy : {sffs_accuracy_rf:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCRJN36d2h-B"
      },
      "source": [
        "# Задание 4. Бинарная классификация с LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlW-ytYP2h-B"
      },
      "source": [
        "В этом задании вам нужно решить задачу бинарной классификации. Используя только [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), добейтесь качества `accuracy` выше 0.91.\n",
        "\n",
        "Что можно:\n",
        "* Генерировать и отбирать признаки\n",
        "\n",
        "Что нельзя:\n",
        "* Менять модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwTInZhW2h-B"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "* Accuracy модели > 0.91.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcuHfeuZ2h-C"
      },
      "source": [
        "Импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qon2hnwJ2h-C"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "matplotlib.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJcAEgPu2h-C"
      },
      "source": [
        "Произведем загрузку данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoT2rAD02h-C"
      },
      "outputs": [],
      "source": [
        "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/feature_engineering_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_et9Ojt2h-C"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/feature_engineering_data.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYezmLJW2h-C"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df)  # to One-Hot Encoding\n",
        "x = df.drop(columns=[\"target\"])\n",
        "y = df[\"target\"]\n",
        "\n",
        "\n",
        "# We make a 80/20% train/test split of the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "print(\"Accuracy of the model = %.2f\" % model.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0nGmCsc2h-C"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(\n",
        "    df,\n",
        "    hue=\"target\",\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c16INtle2h-C"
      },
      "outputs": [],
      "source": [
        "df[\"new_feature_1\"] = df[\"feature_3\"] ** 2\n",
        "df[\"new_feature_2\"] = df[\"feature_5\"] ** 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHVLP7rL2h-C"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df)  # to One-Hot Encoding\n",
        "\n",
        "x = df.drop(columns=[\"target\"])\n",
        "y = df[\"target\"]\n",
        "\n",
        "\n",
        "# We make a 80/20% train/test split of the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "print(\"Accuracy of the model = %.2f\" % model.score(x_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}