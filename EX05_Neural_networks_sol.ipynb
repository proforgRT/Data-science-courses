{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8m5q23IZX1Q"
      },
      "source": [
        "# Вспомогательный код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbiVd37tZX1Q"
      },
      "source": [
        "**Для выполнения задания рекомендуется использовать среду с аппаратным ускорителем GPU.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tawjJTRlZX1R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JUr2DPDZX1R"
      },
      "source": [
        "Блок кода для визуализации процесса обучения модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW-LPiTHZX1R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "class ProgressPlotter:\n",
        "    def __init__(self) -> None:\n",
        "        self._history_dict = defaultdict(list)\n",
        "\n",
        "    def add_scalar(self, tag: str, value) -> None:\n",
        "        self._history_dict[tag].append(value)\n",
        "\n",
        "    def display_keys(self, ax, tags):\n",
        "        if isinstance(tags, str):\n",
        "            tags = [tags]\n",
        "        history_len = 0\n",
        "        ax.grid()\n",
        "        for key in tags:\n",
        "            ax.plot(self._history_dict[key], marker=\"X\", label=key)\n",
        "            history_len = max(history_len, len(self.history_dict[key]))\n",
        "        if len(tags) > 1:\n",
        "            ax.legend(loc=\"lower left\")\n",
        "        else:\n",
        "            ax.set_ylabel(key)\n",
        "        ax.set_xlabel(\"epoch\")\n",
        "        ax.set_xticks(np.arange(history_len))\n",
        "        ax.set_xticklabels(np.arange(history_len))\n",
        "\n",
        "    def display(self, groups=None):\n",
        "        # groups list ofkeys like [['loss_train','loss_val'],['accuracy']]\n",
        "        clear_output()\n",
        "        n_groups = len(groups)\n",
        "        fig, ax = plt.subplots(n_groups, 1, figsize=(12, 3 * n_groups))\n",
        "        if n_groups == 1:\n",
        "            ax = [ax]\n",
        "        for i, keys in enumerate(groups):\n",
        "            self.display_keys(ax[i], keys)\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    @property\n",
        "    def history_dict(self):\n",
        "        return dict(self._history_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOMR1KZvZX1R"
      },
      "source": [
        "Чтобы результаты экспериментов воспроизводились, зафиксируем seed's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zbJ-LIvZX1S"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX2p5FSNZX1S"
      },
      "source": [
        "# Задание 1. Создание полносвязной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qmqCgfTZX1S"
      },
      "source": [
        "1. Создайте двух-трех-слойную* полносвязную нейронную сеть средствами PyTorch.\n",
        "2. Дополните недостающий код для обучения.\n",
        "3. Обучите нейросеть на CIFAR-10.\n",
        "4. Посмотрите график зависимости loss и accuracy от эпохи в процессе обучения.\n",
        "\n",
        "Для создания полносвязных слоев используйте класс [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear).\n",
        "\n",
        "*Рекомендуется использовать скрытый слой со 128 нейронами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u50ZuF-bZX1S"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dplyn_FWZX1S"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy3a1BtOZX1S"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchmetrics\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-S7BxeVZX1S"
      },
      "source": [
        "Загрузим датасет с помощью средств PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m8_40UPZX1S"
      },
      "outputs": [],
      "source": [
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "dataset = CIFAR10(root=\"./CIFAR10\", train=True, download=True, transform=transform)\n",
        "testset = CIFAR10(root=\"./CIFAR10\", train=False, download=True, transform=transform)\n",
        "\n",
        "trainset, valset, _ = random_split(dataset, lengths=[12000, 3000, 35000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0Z5duFBZX1S"
      },
      "source": [
        "Обратите внимание, что для ускорения процесса отладки мы используем только часть обучающих данных. В обучающей выборке CIFAR-10 содержится 50&nbsp;000 изображений. При помощи функции [`random_split`](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) из модуля `torch.utils.data` мы взяли 15&nbsp;000 изображений: 12&nbsp;000 для обучения и 3000 для валидации. Остальные 35&nbsp;000 изображений мы не используем: передаем их в объект с именем&nbsp;`_`. Так стоит поступать в будущем при отладке вашей нейронной сети. Однако после завершения отладки для финального обучения следует использовать все доступные данные, тогда обобщающая способность и качество нейронной сети будут лучше.\n",
        "\n",
        "Также обратите внимание, что сумма значений в параметре `lengths` функции `random_split` должна в точности равняться количеству элементов в датасете, который она разделяет. Поэтому, код\n",
        "\n",
        "`trainset, valset  = random_split(dataset, lengths=[12000, 3000])`\n",
        "\n",
        "выдаст ошибку, так как количество элементов в `dataset` равно 50&nbsp;000, а сумма элементов во втором аргументе функции равна 15&nbsp;000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJiVnX8mZX1S"
      },
      "source": [
        "Опишите структуру сети: полносвязные слои + [функции активации](https://pytorch.org/docs/stable/nn.html?highlight=activation#non-linear-activations-weighted-sum-nonlinearity) на ваш выбор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1E1JtKuZX1T"
      },
      "outputs": [],
      "source": [
        "class FCNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Your code here\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers_stack = nn.Sequential(\n",
        "            nn.Linear(3 * 32 * 32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Your code here\n",
        "        x = self.flatten(x)\n",
        "        logits = self.layers_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Yre2cbZX1T"
      },
      "source": [
        "**Блок обучения.**\n",
        "\n",
        "Обратите внимание на то, что в PyTorch моделях не используется метод fit, как в sklearn. Код, отвечающий за обучение, пишется отдельно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXNcHtKhZX1T"
      },
      "source": [
        "Определим `batch_size` и создадим два DataLoader-а для обучающей и валидационной выборок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgTpto6UZX1T"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmzUQVvWZX1T"
      },
      "source": [
        "Функцию для подсчёта точности возьмем из библиотеки [`torchmetrics`](https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbpJ6PWaZX1T"
      },
      "outputs": [],
      "source": [
        "score_function = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znyGKicHZX1T"
      },
      "source": [
        "**Цикл обучения и валидации.**\n",
        "\n",
        "Определим функции `train_loop` и `val_loop`. Допишите недостающий код. Пользуйтесь материалом лекции.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44flQd5cZX1T"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, criterion, optimizer, score_function, device):\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    train_loss = 0\n",
        "    y_true, y_pred = torch.Tensor(), torch.Tensor()\n",
        "\n",
        "    for imgs, labels in dataloader:\n",
        "        # Compute prediction and loss\n",
        "        pred = model(imgs.to(device))  # Your code here\n",
        "        loss = criterion(pred, labels.to(device))  # Your code here\n",
        "\n",
        "        # Optimization\n",
        "        # Nullify gradients, do a backward and do an optimization step\n",
        "        # Your code here\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # End of your code\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # accumulating true labels to calculate score function\n",
        "        y_true = torch.cat([y_true, labels], dim=0)\n",
        "\n",
        "        # getting predicted labels from logits by argmax\n",
        "        pred_labels = pred.detach().cpu().argmax(dim=1)\n",
        "        # accumulating predicted labels to calculate score function\n",
        "        y_pred = torch.cat([y_pred, pred_labels], dim=0)\n",
        "\n",
        "    train_loss /= num_batches\n",
        "    train_score = score_function(y_pred, y_true)\n",
        "\n",
        "    return train_loss, train_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go2ws9nPZX1T"
      },
      "outputs": [],
      "source": [
        "def val_loop(dataloader, model, criterion, score_function, device):\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    val_loss = 0\n",
        "    y_true, y_pred = torch.Tensor(), torch.Tensor()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            # Compute prediction and loss\n",
        "            pred = model(imgs.to(device))  # Your code here\n",
        "            loss = criterion(pred, labels.to(device))  # Your code here\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # accumulating true labels to calculate score function\n",
        "            y_true = torch.cat([y_true, labels], dim=0)\n",
        "\n",
        "            # getting predicted labels from logits by argmax\n",
        "            pred_labels = pred.detach().cpu().argmax(dim=1)\n",
        "            # accumulating predicted labels to calculate score function\n",
        "            y_pred = torch.cat([y_pred, pred_labels], dim=0)\n",
        "\n",
        "    val_loss /= num_batches\n",
        "    val_score = score_function(y_pred, y_true)\n",
        "\n",
        "    return val_loss, val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8El_eo8IZX1T"
      },
      "source": [
        "Дополните функцию `train` вызовом `train_loop` и `val_loop` внутри цикла по эпохам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAfi0lm2ZX1T"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=10,\n",
        "):\n",
        "    pp = ProgressPlotter()\n",
        "    for i in range(num_epochs):\n",
        "        # properly call train_loop and val_loop\n",
        "        train_loss, train_score = train_loop(\n",
        "            train_loader, model, criterion, optimizer, score_function, device\n",
        "        )  # Your code here\n",
        "\n",
        "        val_loss, val_score = val_loop(\n",
        "            val_loader, model, criterion, score_function, device\n",
        "        )  # Your code here\n",
        "\n",
        "        # logging\n",
        "        pp.add_scalar(\"loss_train\", train_loss)\n",
        "        pp.add_scalar(\"score_train\", train_score)\n",
        "\n",
        "        pp.add_scalar(\"loss_val\", val_loss)\n",
        "        pp.add_scalar(\"score_val\", val_score)\n",
        "\n",
        "        pp.display([[\"loss_train\", \"loss_val\"], [\"score_train\", \"score_val\"]])\n",
        "    return pp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7rQ6D_PZX1T"
      },
      "source": [
        "Создание экземпляра модели, определение оптимизатора, функции потерь, и собственно запуск обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MXm2u9tZX1T"
      },
      "outputs": [],
      "source": [
        "model = FCNet().to(device)  # Create model instance and move it to device\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)  # Weights update algorithm\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPyhuZZNZX1U"
      },
      "source": [
        "Функция `train` возвращает объект `ProgressPlotter`, который имеет атрибут `.history_dict` — словарь, в котором хранится история обучения модели: значение функции потерь и точности на обучающих и валидационных данных по эпохам.\n",
        "\n",
        "По ключу `score_val` можно извлечь из словаря значения точности на валидационных данных по эпохам и вывести итоговую точность модели, достигнутую на последней (`-1`-й) эпохе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOCzyxjoZX1U"
      },
      "outputs": [],
      "source": [
        "accuracy = pp.history_dict[\"score_val\"][-1]\n",
        "print(f\"Accuracy {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMNEKeqnZX1U"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFTKfe_5ZX1U"
      },
      "source": [
        "График обучения сети.\n",
        "\n",
        "Пример графика:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/Exercises/EX05/result_1_task_ex05.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34v9NFsaZX1U"
      },
      "source": [
        "# Задание 2. Нормализация данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZGEflTQZX1U"
      },
      "source": [
        "Стандартизируйте данные.\n",
        "\n",
        "* Подсчитайте среднее значение и стандартное отклонение для каждого из 3-х цветовых каналов\n",
        " * Сделайте это с помощью встроенных в PyTorch или NumPy функций\n",
        "* Нормализуйте данные с использованием этих параметров (используйте трансформацию `Normalize`[🛠️[doc]](https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html))\n",
        "* Оцените влияние нормировки данных на точность обучения (сравните результаты обучения на сырых данных в задании №1 и на стандартизованных)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWmgFCSUZX1U"
      },
      "source": [
        "Посмотрим на размерность тензора с обучающими данными"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoBVNi44ZX1U"
      },
      "outputs": [],
      "source": [
        "print(dataset.data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh-VoOm3ZX1c"
      },
      "source": [
        "Вычислите средние и стандартные отклонения **по каждому из трех цветовых каналов** для обучающих данных.\n",
        "\n",
        "Каждый канал изображения стандартизуется независимо. Поэтому каждый из объектов `cifar10_mean` и `cifar10_std` должен представлять из себя последовательность (`list` / `np.ndarray` / `torch.Tensor`) длиной в количество каналов.\n",
        "\n",
        "Также не забудьте, что `Normalize` будет применяться после `ToTensor` и поэтому средние и стандартные отклонения должны быть отмасштабированы в $[0,1]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj5OBdxyZX1c"
      },
      "outputs": [],
      "source": [
        "cifar10_mean = dataset.data.mean(axis=(0, 1, 2)) / 255  # Your code here\n",
        "cifar10_std = dataset.data.std(axis=(0, 1, 2)) / 255  # Your code here\n",
        "print(f\"Mean: {cifar10_mean}, Std: {cifar10_std}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0qrtw7oZX1c"
      },
      "source": [
        "Создайте трансформацию, которая включает в себя нормализацию, и подмените трансформацию в обучающем и тестовом Dataset-ах на новую."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zyC1K8ZZX1c"
      },
      "source": [
        "**Внимание! Неочевидная особенность!**\n",
        "\n",
        "Атрибут `.transform` необходимо переопределить не у объектов `trainset` и `valset`, а у объекта `dataset`, из которого `trainset` и `valset` были случайно отобраны с помощью функции `random_split` в задании №1.\n",
        "\n",
        "Функция `random_split` возвращает объекты класса `Subset`, которые не имеют своих трансформаций, а используют трансформации, определенные родительском в `Dataset`-е."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88mIXkJNZX1c"
      },
      "outputs": [],
      "source": [
        "transform_with_normalize = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.ToTensor(),  # [0..255] -> [0..1]\n",
        "        torchvision.transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "    ]\n",
        ")  # Your code here\n",
        "\n",
        "# Your code here\n",
        "dataset.transform = transform_with_normalize\n",
        "testset.transform = transform_with_normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN81-ZPtZX1c"
      },
      "source": [
        "Снова создайте экземпляр модели, определите оптимизатор и функцию потерь, и вызовите функцию для обучения (можно скопировать код из задания 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmcpPoY0ZX1c"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "model = FCNet().to(device)  # Create model instance and move it to device\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)  # Weights update algorithm\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kX4UWp_ZX1c"
      },
      "source": [
        "Выведите итоговую точность на валидационных данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVK3txh7ZX1d"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "accuracy = pp.history_dict[\"score_val\"][-1]\n",
        "print(f\"Accuracy {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNG2RmhdZX1d"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bggWLl67ZX1d"
      },
      "source": [
        "График обучения сети.\n",
        "\n",
        "Пример графика:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/Exercises/EX05/result_2_task_ex05.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqherCgvZX1d"
      },
      "source": [
        "# Задание 3. Повышение точности классификатора"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvq4FVbHZX1d"
      },
      "source": [
        "Классифицируйте CIFAR-10 с максимальной точностью.\n",
        "\n",
        "Для этого:\n",
        "\n",
        "*  Используйте весь датасет для обучения\n",
        "*  Примените нормализацию к данным\n",
        "*  Подберите шаг обучения\n",
        "*  Обучайте сеть порядка 25 эпох\n",
        "*  При необходимости можете добавить в модель еще один скрытый слой\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFZeyjJ9ZX1d"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "trainset, valset = random_split(dataset, [45000, 5000])\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "cifar10_mean = dataset.data.mean(axis=(0, 1, 2)) / 255\n",
        "cifar10_std = dataset.data.std(axis=(0, 1, 2)) / 255\n",
        "\n",
        "transform_with_normalize = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.ToTensor(),  # [0..255] -> [0..1]\n",
        "        torchvision.transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset.transform = transform_with_normalize\n",
        "testset.transform = transform_with_normalize\n",
        "\n",
        "model = FCNet().to(device)  # Create model instance and move it to device\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005)  # Weights update algorithm\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=25,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k09sOcFkZX1d"
      },
      "source": [
        "Оцените точность на **тестовом** датасете (`testset`).\n",
        "\n",
        "Для этого **создайте DataLoader для тестовых данных**. Для оценки точности можно воспользоваться функцией `val_loop`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRhBS6k2ZX1d"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "_, test_accuracy = val_loop(test_loader, model, criterion, score_function, device)\n",
        "print(f\"Accuracy on TEST {test_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4BjB5R_ZX1d"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBJnu7vwZX1d"
      },
      "source": [
        "Выведите графики как в первом задании. Вы должны получить точность 0.48 .. 0.52"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p76dFA50ZX1d"
      },
      "source": [
        "# Задание 4. Техники для работы в условиях дисбаланса классов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCcNX5lpZX1d"
      },
      "source": [
        "В этом задании вам предлагается решить задачу классификации на несбалансированном датасете [Car Evaluation](https://archive.ics.uci.edu/dataset/19/car+evaluation).\n",
        "\n",
        "Требуется обучить полносвязную нейронную сеть, сделав бейзлайн с функцией потерь `CrossEntropyLoss`, а затем реализовать различные техники для работы в условиях дисбаланса:\n",
        "\n",
        "1. `CrossEntropyLoss` **с весами для классов**,\n",
        "2. `FocalLoss`,\n",
        "3. `FocalLoss` **с весами для классов**,\n",
        "4. `WeightedRandomSamlper` при функции потерь `CrossEntropyLoss`,\n",
        "5. `WeightedRandomSamlper` при функции потерь `FocalLoss`,\n",
        "\n",
        "сравнить их между собой и сделать выводы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmTh3UKvZX1d"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ccBGZF0ZX1d"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5q5Td-zZX1e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchmetrics\n",
        "import pandas as pd\n",
        "\n",
        "from torch import nn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiGzEXuIZX1e"
      },
      "source": [
        "## Обзор датасета и подготовка данных для обучния\n",
        "\n",
        "Загрузим датасет и взглянем на него:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opf-halFZX1e"
      },
      "outputs": [],
      "source": [
        "# !wget -qN https://archive.ics.uci.edu/static/public/19/car+evaluation.zip\n",
        "!wget -qN https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/car_evaluation.zip\n",
        "!unzip -qo car_evaluation.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP7WcNmpZX1e"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\n",
        "    \"car.data\",\n",
        "    names=[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"],\n",
        ")\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzLwuHZ6ZX1e"
      },
      "source": [
        "В архиве найдем текстовый файл с описанием датасета `car.names`. Выведем его:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7MDjmAwZX1e"
      },
      "outputs": [],
      "source": [
        "!cat car.names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSLmgIjiZX1e"
      },
      "source": [
        "В датасете содержится 1728 наблюдений об автомобилях, которые описываются шестью категориальными признаками:\n",
        "1. `buying` — стоимость покупки\n",
        "2. `maint` — стоимость обслуживания\n",
        "3. `doors` — количество дверей\n",
        "4. `persons` — количество пассажиров\n",
        "5. `lug_boot` — размер багажника\n",
        "6. `safety` — оценка безопасности машины.\n",
        "\n",
        "Также имеется целевой признак `class` с четырьмя уникальными значениями:\n",
        "\n",
        "* `unacc` — неприемлемо\n",
        "* `acc` — приемлемо\n",
        "* `good` — хорошо\n",
        "* `vgood` — отлично\n",
        "\n",
        "Оценим баланс классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzaTFu6sZX1e"
      },
      "outputs": [],
      "source": [
        "data[\"class\"].hist()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymQaHvZWZX1e"
      },
      "source": [
        "Посмотрим на описательные статистики по признакам:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mg0go1MZX1e"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCrbmJooZX1e"
      },
      "source": [
        "Все входные признаки в датасете — категориальные, поэтому предварительно нужно их закодировать. Воспользуемся [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)-ом для кодирования входных признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp0XeRM4ZX1e"
      },
      "outputs": [],
      "source": [
        "# split data to input x and target y\n",
        "x, y = data.iloc[:, :-1], data.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW66tziAZX1e"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "x_encoded = encoder.fit_transform(x)\n",
        "\n",
        "x_encoded.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-OI4HK5ZX1e"
      },
      "source": [
        "Классы просто закодируем порядковыми числами:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA41v9X_ZX1f"
      },
      "outputs": [],
      "source": [
        "classes = [\"unacc\", \"acc\", \"good\", \"vgood\"]\n",
        "class_labels = [0, 1, 2, 3]\n",
        "class_to_idx = dict(zip(classes, class_labels))\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajIgYq9bZX1f"
      },
      "outputs": [],
      "source": [
        "y_encoded = y.map(class_to_idx)  # mapping class names into their indexes\n",
        "y_encoded = y_encoded.values  # transform Pandas Series into numpy array\n",
        "y_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LqWf4lfZX1f"
      },
      "source": [
        "Разделим данные на обучающие и тестовые в соотношении 80/20 и переведем их в `torch.tensor`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBs6jNsXZX1f"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_encoded, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jkNLmfRZX1f"
      },
      "source": [
        "Создадим `Dataset`-ы и `DataLoader`-ы для обучения нейросетей.\n",
        "\n",
        "Обучающие и тестовые данные представляют из себя уже предобработанные тензоры. Поэтому для создания `Dataset`-ов можно воспользоваться классом [`TensorDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaj9frb-ZX1f"
      },
      "outputs": [],
      "source": [
        "trainset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(x_test, y_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdFJ922mZX1f"
      },
      "source": [
        "Напишите архитектуру полносвязной сети для этого датасета. Рекомендуется использовать 1–2 скрытых слоя из 5–10 нейронов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViWTRY1CZX1f"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Your code here\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(21, 10), nn.ReLU(), nn.Linear(10, 4))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Your code here\n",
        "        out = self.net(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmdOzMPkZX1f"
      },
      "source": [
        "## Показатель качества при дисбалансе"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04S-5sSDZX1f"
      },
      "source": [
        "Так как набор данных несбалансирован, оценивать качество модели по accuracy будет некорректно. В качетсве фукнции оценки можем выбрать F1-score. Его реализацию для удобства возьмем из [`torchmetrics`](https://torchmetrics.readthedocs.io/en/stable/classification/f1_score.html#f-1-score):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZrHo1WsZX1f"
      },
      "outputs": [],
      "source": [
        "score_function = torchmetrics.F1Score(task=\"multiclass\", num_classes=4, average=\"macro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZpCSXZKZX1f"
      },
      "source": [
        "## Бейзлайн c кросс-энтропией\n",
        "\n",
        "Далее будет серия экспериментов по обучению нейросети на этом датасете с применением различных техник работы в условиях дисбаланса классов.\n",
        "Для начала обучите бейзлайн с `CrossEntropyLoss`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfNN35EVZX1f"
      },
      "outputs": [],
      "source": [
        "set_random_seed(42)\n",
        "\n",
        "model = Network().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Your code here\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4iUxNxKZX1f"
      },
      "source": [
        "Напишем функцию для прогона DataLoader-a через модель и получения предсказаний."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiJnTlJAZX1g"
      },
      "outputs": [],
      "source": [
        "def get_true_and_pred(dataloader, model):\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for input, target in dataloader:\n",
        "        y_true.append(target)\n",
        "        output = model(input.to(device))\n",
        "        output = torch.argmax(output.cpu().detach(), dim=1)\n",
        "        y_pred.append(output)\n",
        "\n",
        "    y_true = np.array(torch.cat(y_true))\n",
        "    y_pred = np.array(torch.cat(y_pred))\n",
        "\n",
        "    return y_true, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gOolgiZZX1g"
      },
      "source": [
        "Выведем отчет о качестве классификации тестовой выборки с помощью [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U5mCK24ZX1g"
      },
      "outputs": [],
      "source": [
        "y_test_true, y_test_pred = get_true_and_pred(test_loader, model)\n",
        "\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test_true, y_test_pred, target_names=classes, zero_division=0\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-qqjjSuZX1g"
      },
      "source": [
        "Также посмотрим на матрицу ошибок ([`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)). Отобразим ее с помощью [`ConfusionMatrixDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3grejjdqZX1g"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUHTLRnvZX1g"
      },
      "source": [
        "Опишите результаты классификации. Какие проблемы вы наблюдаете?\n",
        "\n",
        "***Your text here***\n",
        "\n",
        "Классы good и vgood не предсказываются совсем.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDbqZ0uZZX1g"
      },
      "source": [
        "## Кросс-энтропия с весами для классов\n",
        "\n",
        "Вам нужно создать одномерный тензор `weights_for_classes` с весами для классов. В качестве весов можно взять величины, обратные к количеству объектов определенного класса в обучающей выборке.\n",
        "\n",
        "**Обратите внимание**, тензор с весами `weights_for_classes` должен быть перенесен на `device`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoiT-TpdZX1g"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "_, classes_counts = torch.unique(\n",
        "    y_train, return_counts=True\n",
        ")  # y_train — tensor of labels in train set\n",
        "\n",
        "weights_for_classes = classes_counts.max() / classes_counts\n",
        "\n",
        "weights_for_classes = weights_for_classes.to(device)\n",
        "\n",
        "weights_for_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE3b-3xnZX1g"
      },
      "source": [
        "Обучите модель с `CrossEntropyLoss`, передав ей в качестве аргумента `weight` тензор `weights_for_classes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD7z9_hdZX1g"
      },
      "outputs": [],
      "source": [
        "set_random_seed(42)\n",
        "\n",
        "model = Network().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_for_classes)  # Your code here\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa6UjcD_ZX1g"
      },
      "source": [
        "Оцените качество обработки тестовой выборки с помощью отчета о классификации и матрицы ошибок."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xffWC-pfZX1g"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "y_test_true, y_test_pred = get_true_and_pred(test_loader, model)\n",
        "\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test_true, y_test_pred, target_names=classes, zero_division=0\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOvs77GsZX1g"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "disp1.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BRt9EJiZX1g"
      },
      "source": [
        "Опишите, как изменилось качество классификации.\n",
        "\n",
        "***Your text here***\n",
        "\n",
        "Добавление весов в функцию потерь позволяет исправить ситуацию и предсказывать минорные классы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM5lLSVGZX1g"
      },
      "source": [
        "## Focal Loss\n",
        "\n",
        "Воспользуйтесь Focal Loss в качестве функции потерь подобно тому, как вы сделали в бейзлайне с кросс-энтропией.\n",
        "\n",
        "В этом пункте **не используйте** веса для классов. Параметр $\\gamma$ примите равным $2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9-iVHxPZX1g"
      },
      "outputs": [],
      "source": [
        "#!wget -qN https://raw.githubusercontent.com/AdeelH/pytorch-multi-class-focal-loss/master/focal_loss.py\n",
        "!wget -qN https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/Exercises/EX05/focal_loss.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYYI1Y5FZX1h"
      },
      "source": [
        "Информация из [документации](https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/focal_loss.py):\n",
        "\n",
        "* `alpha` (*Tensor*, optional): Weights for each class. Defaults to `None`.\n",
        "* `gamma` (*float*, optional): A constant, as described in the paper. Defaults to `0`.\n",
        "* `reduction` (*str*, optional): `'mean'`, `'sum'` or `'none'`. Defaults to `'mean'`.\n",
        "* `ignore_index` (*int*, optional): class label to ignore. Defaults to `-100`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BweQfMS_ZX1h"
      },
      "outputs": [],
      "source": [
        "from focal_loss import FocalLoss\n",
        "\n",
        "\n",
        "set_random_seed(42)\n",
        "\n",
        "model = Network().to(device)\n",
        "\n",
        "criterion = FocalLoss(alpha=None, gamma=2.0)  # Your code here\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fExM7fpfZX1h"
      },
      "source": [
        "Оцените качество на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s1bMtE-ZX1h"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "y_test_true, y_test_pred = get_true_and_pred(test_loader, model)\n",
        "\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test_true, y_test_pred, target_names=classes, zero_division=0\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCArF9_JZX1h"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "disp2.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq59uSGgZX1h"
      },
      "source": [
        "Опишите, как изменилось качество классификации.\n",
        "\n",
        "***Your text here***\n",
        "\n",
        "Так же, как и с кросс-энтроприей, обучение с Focal loss без весов для классов не помогает при классификации объектов минорных классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSwxQHuCZX1h"
      },
      "source": [
        "## Focal Loss с весами для классов\n",
        "\n",
        "Обучите модель с Focal Loss, передав ей в качестве парамета `alpha` тензор весов `weights_for_classes`. Как и в прошлом пункте, используйте $\\gamma=2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY6pGu0SZX1h"
      },
      "outputs": [],
      "source": [
        "set_random_seed(42)\n",
        "\n",
        "model = Network().to(device)\n",
        "\n",
        "criterion = FocalLoss(alpha=weights_for_classes, gamma=2.0)  # Your code here\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS-dvNotZX1h"
      },
      "source": [
        "Оцените качество на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOSQ9RyhZX1h"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "y_test_true, y_test_pred = get_true_and_pred(test_loader, model)\n",
        "\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test_true, y_test_pred, target_names=classes, zero_division=0\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTjU6lGoZX1h"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "disp3.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95QKXnCzZX1h"
      },
      "source": [
        "Опишите, как изменилось качество классификации.\n",
        "\n",
        "***Your text here***\n",
        "\n",
        "Так же, как и с кросс-энтроприей, обучение с Focal loss с весами для классов позволяет классифицировать объекты минорных классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqjsEJQHZX1h"
      },
      "source": [
        "## Weighted Random Sampler + Cross-Entropy Loss\n",
        "\n",
        "Балансировать классы с помощью весов можно не только указывая их в функции потерь, но также и при формировании батчей.\n",
        "\n",
        "Weighted Random Sampler занимается тем, что при формировании батчей учитывает веса разных объектов. Тем самым мы получаем возможность показывать модели объекты минорных классов чаще."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELPRgpUFZX1h"
      },
      "source": [
        "Особенность работы с Weighted Random Sampler в том, что ему нужно передать **веса для каждого объекта** в соответствии с тем, к какому классу этот объект относится. Создайте такой тензор весов `weight_for_every_sample`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6dkcH4JZX1h"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "weight_for_every_sample = []  # Every sample must have a weight\n",
        "for label in y_train:\n",
        "    weight_for_every_sample.append(weights_for_classes[label].item())\n",
        "\n",
        "weight_for_every_sample = torch.tensor(weight_for_every_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PadKrHe-ZX1i"
      },
      "source": [
        "Теперь нужно создать `sampler`.\n",
        "\n",
        "`WeightedRandomSampler`-у при инициализации нужно передать массив весов для каждого объекта, а также параметр `num_samples` — количество объектов для выдачи за одну эпоху. Этот параметр можно принять равным длине обучающей выборки.\n",
        "\n",
        "Далее нужно заново создать обучающий `DataLoader`, и передать ему взвешенный `sampler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMRSQT70ZX1i"
      },
      "outputs": [],
      "source": [
        "sampler = WeightedRandomSampler(\n",
        "    weight_for_every_sample, num_samples=len(y_train)\n",
        ")  # Your code here\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=32, sampler=sampler\n",
        ")  # Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK0Yw9OGZX1i"
      },
      "source": [
        "Обучите модель с Cross-Entropy Loss **без весов для классов**, используя созданный выше `DataLoader` со взвешенным сэмплером. Обратите внимание, что мы уже учли дисбаланс во взвешенном сэмплере, поэтому указывать веса в функции потерь не нужно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s68mbczaZX1i"
      },
      "outputs": [],
      "source": [
        "model = Network().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Your code here\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpAGZZqqZX1i"
      },
      "source": [
        "Оцените качество на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YXiRFxuZX1i"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "y_test_true, y_test_pred = get_true_and_pred(test_loader, model)\n",
        "\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test_true, y_test_pred, target_names=classes, zero_division=0\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vozEj9mYZX1i"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "\n",
        "disp4 = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "disp4.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zoEM_k7ZX1i"
      },
      "source": [
        "Опишите, как изменилось качество классификации.\n",
        "\n",
        "***Your text here***\n",
        "\n",
        "Использование взвешенного сэмплера тоже позволяет получать предсказания для минорных классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s1s8J7jZX1i"
      },
      "source": [
        "## Weighted Random Sampler + Focal Loss\n",
        "\n",
        "Повторите обучение с Focal Loss, используя уже созданный `DataLoader` со взвешенным сэмплером."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e8cjV5rZX1i"
      },
      "outputs": [],
      "source": [
        "model = Network().to(device)\n",
        "\n",
        "criterion = FocalLoss(alpha=None, gamma=2.0)  # Your code here\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "pp = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    score_function,\n",
        "    device,\n",
        "    num_epochs=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdw3BTcWZX1i"
      },
      "source": [
        "Оцените качество на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5qBgoJeZX1i"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "y_test_true, y_test_pred = get_true_and_pred(test_loader, model)\n",
        "\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test_true, y_test_pred, target_names=classes, zero_division=0\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66ESMxybZX1i"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "\n",
        "disp5 = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "disp5.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVEDZrMOZX1j"
      },
      "source": [
        "Опишите, как изменилось качество классификации.\n",
        "\n",
        "***Your text here***\n",
        "Как и в случае с кросс-энтроприей, использование взвешенного сэмплера позволяет получать предсказания для минорных классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GozIfSt7ZX1j"
      },
      "source": [
        "## Сравнение результатов\n",
        "\n",
        "Сравните результаты классификации тестовой выборки при обучении моделей с разными техниками борьбы с дисбалансом. В качестве меры сравнения можно выбрать *macro F-1 score*, который выводится в `classification_report`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAttsKisZX1j"
      },
      "outputs": [],
      "source": [
        "displays = [disp, disp1, disp2, disp3, disp4, disp5]\n",
        "titles = [\n",
        "    \"Baseline CE\",\n",
        "    \"Weighted CE\",\n",
        "    \"Focal\",\n",
        "    \"Weighted Focal\",\n",
        "    \"WRS + CE\",\n",
        "    \"WRS + Focal\",\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 6, figsize=(15, 10), sharey=\"row\")\n",
        "\n",
        "for i, displ in enumerate(displays):\n",
        "    displ.plot(ax=axes[i], xticks_rotation=45)\n",
        "    displ.ax_.set_title(titles[i])\n",
        "    displ.im_.colorbar.remove()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73K4RmQoZX1j"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE0r5GGXZX1j"
      },
      "source": [
        "Результатом выполнения задания является обучение модели с шестью техниками:\n",
        "0. Бейзлайн с кросс-энтропией\n",
        "1. Кросс-энтропия с весами для классов\n",
        "2. Focal Loss\n",
        "3. Focal Loss с весами для классов\n",
        "4. Weighted Random Sampler + кросс-энтропия\n",
        "5. Weighted Random Sampler + Focal Loss\n",
        "\n",
        "Для каждого обучения требуется вывести отчет о качестве классификации тестовой выборки и матрицу ошибок.\n",
        "В конце требуется сравнить качество классификации по метрике *macro F-1 score*."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}