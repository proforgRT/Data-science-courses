{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpiq14aGxXdm"
      },
      "source": [
        "# Распределение баллов\n",
        "\n",
        "Задание 1: до **40** баллов\n",
        "\n",
        "Задание 2: до **40** баллов\n",
        "\n",
        "Дополнительно: до **20** баллов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2fQa7ZrxXdo"
      },
      "source": [
        "# Задание 1. Классификация спутниковых снимков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKRC0bc0xXdo"
      },
      "source": [
        "В этом задании мы будем работать с [**EuroSAT Dataset**](https://github.com/phelber/eurosat). В датасете представлены космоснимки со спутника Sentinel-2, которые находятся в открытом и свободном доступе в рамках программы наблюдения Земли — Copernicus. Датасет охватывает 13 спектральных диапазонов и состоит из 10 классов с общим количеством 27 000 размеченых и привязанных к местности изображений.\n",
        "\n",
        "Загрузите непредобученную сеть `efficientnet_lite0.ra_in1k` и обучите ее. Посчитайте метрики на тестовом датасете."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAYN4UOJxXdo"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "\n",
        "* Значение метрики на тестовом датасете\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-68KZQbzxXdp"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiCEDWmyxXdp"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchsat torchinfo\n",
        "!pip install -q timm lightning torchmetrics torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0ArHBUaxXdq"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchmetrics\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import lightning as L\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsat.datasets.eurosat import EuroSAT\n",
        "\n",
        "from torchmetrics import MetricCollection\n",
        "from torchmetrics.classification import (\n",
        "    MulticlassAccuracy, MulticlassF1Score, MulticlassAUROC,\n",
        ")\n",
        "\n",
        "L.seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvO_RBfqxXdq"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRrab3o8xXdq"
      },
      "source": [
        "Воспользуемся пакетом [torchsat](https://torchsat.readthedocs.io/en/latest/index.html) для работы с датасетом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp2bKfxfxXdq"
      },
      "source": [
        "Загрузка данных в нем пока не поддерживается :( придется загрузить и распаковать архив самостоятельно:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLNgmglPxXdq"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/eurosat-ms\n",
        "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/EuroSATallBands.zip\n",
        "!unzip -q EuroSATallBands.zip -d /content/eurosat-ms\n",
        "!rm EuroSATallBands.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_BkV6qbxXdq"
      },
      "outputs": [],
      "source": [
        "from torchsat.datasets.eurosat import EuroSAT\n",
        "\n",
        "dataset = EuroSAT(root=\"/content/eurosat-ms/ds/\", mode=\"AllBand\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGHVJSKxXdq"
      },
      "source": [
        "Создадим файл `annotation.csv` для разделения объектов на tran/test/val выборки и их фиксации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cqTg-fhxXdq"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "annotation = []\n",
        "img_paths = Path('/content/eurosat-ms/ds/images/remote_sensing/otherDatasets/sentinel_2/').glob('**/*.tif')\n",
        "for item in img_paths:\n",
        "    row = {}\n",
        "    row['img_path'] = item\n",
        "    row['class'] = item.parent.stem\n",
        "    annotation.append(row)\n",
        "annotation = pd.DataFrame(annotation)\n",
        "annotation.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h91LOtxgxXdr"
      },
      "outputs": [],
      "source": [
        "annotation['class_idx'] = pd.get_dummies(annotation['class']).apply(lambda row: np.argmax(row), axis=1)\n",
        "class_idx_to_class_name = {class_idx: class_name for class_idx, class_name in enumerate(pd.get_dummies(annotation['class']).columns)}\n",
        "annotation.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzwvB96exXdr"
      },
      "outputs": [],
      "source": [
        "class_idx_to_class_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9eyuqcyxXdr"
      },
      "source": [
        "Сделаем разделение на выборки. Уменьшим количество объектов для обучения, чтобы смоделировать ситуацию малого количества данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te8IWq4OxXdr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train, x, y_train, y = train_test_split(\n",
        "    annotation['img_path'], annotation['class'], test_size=0.98, random_state=42,\n",
        "    stratify=annotation['class']\n",
        ")\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x, y, test_size=0.9, random_state=42, stratify=y\n",
        ")\n",
        "print('train shape: ', x_train.shape)\n",
        "print('val shape: ', x_val.shape)\n",
        "print('test shape: ', x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Uu_TJMxXdr"
      },
      "source": [
        "Сохраним аннотации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1Kd50aRxXdr"
      },
      "outputs": [],
      "source": [
        "annotation.iloc[x_train.index].to_csv('train_eurosat.csv', index=False)\n",
        "annotation.iloc[x_val.index].to_csv('val_eurosat.csv', index=False)\n",
        "annotation.iloc[x_test.index].to_csv('test_eurosat.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4hkufcexXdr"
      },
      "source": [
        "Напишем свой `CustomImageDataset`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_YZH1whxXdr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tifffile as tff\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        annotations_csv,\n",
        "        transforms=None,\n",
        "    ):\n",
        "        self.annotation = pd.read_csv(annotations_csv)\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotation)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = tff.imread(self.annotation.loc[idx, 'img_path'])\n",
        "        label = self.annotation.loc[idx, 'class_idx']\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        label = torch.as_tensor(label).long()\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdnIHsQ3xXdr"
      },
      "outputs": [],
      "source": [
        "train_set = CustomImageDataset('/content/train_eurosat.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGHj_vmGxXdr"
      },
      "source": [
        "## Предварительный анализ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTO1d3XCxXdr"
      },
      "source": [
        "Посмотрим, что мы скачали"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JdnnCXvxXdr"
      },
      "outputs": [],
      "source": [
        "print(\"Image count: \", len(train_set))\n",
        "image, label = train_set[0]\n",
        "print(\"Type: \", type(image),\n",
        "      \"\\nshape\", image.shape,\n",
        "      \"\\nClass\", class_idx_to_class_name[label.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-JamYhfxXds"
      },
      "source": [
        "Ага! У нас не 3 канала, как в обычном RGB, а 13! Давайте на них посмотрим"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ0C7SlyxXds"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols=13, figsize=(20, 3))\n",
        "for band, a in enumerate(ax):\n",
        "    a.imshow(image[:, :, band])\n",
        "    a.axis(\"off\")\n",
        "    a.set_title(\"Band %i\" % band)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-ZktlG2xXds"
      },
      "source": [
        "Что значат эти Bands?\n",
        "\n",
        "* Band 0 – Coastal aerosol\n",
        "* Band 1 – Blue\n",
        "* Band 2 – Green\n",
        "* Band 3 – Red\n",
        "* Band 4–6 – Vegetation red edge\n",
        "* Band 7 – NIR (near infrared range)\n",
        "* Band 8 – Narrow NIR\n",
        "* Band 9 – Water vapour\n",
        "* Band 10–12 – SWIR (short wave infrared spectral range)\n",
        "\n",
        "Вооружившись этим знанием, посмотрим на картинки снова:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDhFHWHwxXds"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols=7, figsize=(20, 3))\n",
        "\n",
        "ax[0].imshow(image[:, :, 0], cmap=\"Greys\")\n",
        "ax[0].set_title(\"Coastal aerosol\")\n",
        "\n",
        "# get 1 image from 3 channel\n",
        "b = image[:, :, 1] / image[:, :1].max()  # Normalize at 0 to 1\n",
        "g = image[:, :, 2] / image[:, :2].max()\n",
        "r = image[:, :, 3] / image[:, :3].max()\n",
        "rgb = np.stack((r, g, b))\n",
        "rgb = np.moveaxis(rgb, [0, 1, 2], [2, 0, 1])  # 3,64,64 -> 64,64,3 like permute(1,2,0)\n",
        "\n",
        "ax[1].imshow(rgb)\n",
        "ax[1].set_title(\"RGB\")\n",
        "\n",
        "ax[2].imshow(image[:, :, 4:6].sum(axis=2), cmap=\"inferno\")\n",
        "ax[2].set_title(\"Vegitation\")\n",
        "\n",
        "ax[3].imshow(image[:, :, 7], cmap=\"inferno\")\n",
        "ax[3].set_title(\"NIR\")\n",
        "\n",
        "ax[4].imshow(image[:, :, 8], cmap=\"inferno\")\n",
        "ax[4].set_title(\"NIR Narrow\")\n",
        "\n",
        "ax[5].imshow(image[:, :, 9], cmap=\"Blues\")\n",
        "ax[5].set_title(\"Water vapour\")\n",
        "\n",
        "ax[6].imshow(image[:, :, 10:].sum(axis=2), cmap=\"inferno\")\n",
        "ax[6].set_title(\"SWIR\")\n",
        "for a in ax:\n",
        "    a.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8raO-10xXds"
      },
      "source": [
        "## Подготовка к обучению"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mNg7j63xXds"
      },
      "source": [
        "Посчитаем среднее и стандартное отклонение, чтобы нормализовать данные. Данных много, и они могут не поместиться в память целиком. Придется считывать частями:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gHky57XxXds"
      },
      "source": [
        "Считать std как среднее от стандартных отклонений по batch-ам не вполне корректно. Поэтому используем [альтернативный способ](https://stackoverflow.com/questions/10365119/mean-value-and-standard-deviation-of-a-very-huge-data-set).\n",
        "\n",
        "Дисперсия:\n",
        "\n",
        "$ Var(X) = E[X^{2}] - (E[X])^2$\n",
        "\n",
        "$ std = \\sqrt{Var}$\n",
        "\n",
        "Для него потребуется хранить сумму квадратов всех заначений, что теоретически может привести к переполнению."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7O0pl3IxXds"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "mean_on_img = [train_set[idx][0].mean(axis=(0, 1)) for idx in tqdm(range(len(train_set)))]\n",
        "mean_squared_on_img = np.power(mean_on_img, 2)\n",
        "squared_mean = np.mean(mean_squared_on_img, axis=0)\n",
        "\n",
        "mean = np.mean(mean_on_img, axis=0)\n",
        "std = np.sqrt(squared_mean - mean**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdm3QFxZxXds"
      },
      "source": [
        "\n",
        "\n",
        "Dataloader не сможет преобразовать uint16 numpy массив к тензору и выдаст ошибку. Стандартный ToTensor рассчитан на работу с картинками, где значения яркости находятся в интервале 0 .. 255, и тоже не сработает. Придется добавить к датасету трансформацию, которая преобразует значения во float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbYJC2glxXds"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "all_transforms = transforms.Compose([\n",
        "    transforms.Lambda(lambda np_arr: np_arr.astype(np.float32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "train_set = CustomImageDataset('/content/train_eurosat.csv', transforms=all_transforms)\n",
        "val_set = CustomImageDataset('/content/val_eurosat.csv', transforms=all_transforms)\n",
        "test_set = CustomImageDataset('/content/test_eurosat.csv', transforms=all_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JjpCWrCxXds"
      },
      "source": [
        "Нам не всегда нужны одинаковые `transforms` для каждой подвыборки,  поэтому в `torchvision`  можно добавлять `transforms` в уже созданый [список](https://discuss.pytorch.org/t/cannot-combine-compose-transforms/32157/5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61e8x2VRxXds"
      },
      "source": [
        "Инициализируем загрузчики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcOT9ZXpxXdy"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgBpHp3-xXdy"
      },
      "source": [
        "##  Обучите сеть\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flgOP3WbxXdy"
      },
      "outputs": [],
      "source": [
        "class LModel(L.LightningModule):\n",
        "    def __init__(self, model, lr=0.001, gamma=0.9):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(logger=False)\n",
        "\n",
        "        # for optimizer and shaduler\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # model\n",
        "        self.model = model\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # metrics\n",
        "        self.metrics = MetricCollection([\n",
        "            MulticlassAccuracy(num_classes=10,),\n",
        "            MulticlassF1Score(num_classes=10,),\n",
        "        ])\n",
        "        self.train_metrics = self.metrics.clone(postfix='/train')\n",
        "        self.val_metrics = self.metrics.clone(postfix='/val')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # set optimizer\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.lr,\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"interval\": \"epoch\",  # or 'step'\n",
        "                \"monitor\": \"loss\" # only for self.log\n",
        "            },\n",
        "        }\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        self.train_metrics.update(out.softmax(-1), y)\n",
        "        self.log(\"loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        self.val_metrics.update(out.softmax(-1), y)\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log_dict(self.train_metrics.compute())\n",
        "        self.train_metrics.reset()\n",
        "\n",
        "        self.log_dict(self.val_metrics.compute())\n",
        "        self.val_metrics.reset()\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        self.metrics.update(out.softmax(-1), y)\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log_dict(self.metrics.compute())\n",
        "        self.metrics.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcw2U4LtxXdy"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "\n",
        "model = timm.create_model(\n",
        "    \"efficientnet_lite0.ra_in1k\", pretrained=False, num_classes=10, in_chans=13\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnN3Ap4cxXdy"
      },
      "outputs": [],
      "source": [
        "pl_model = LModel(model)\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=3,\n",
        "    num_sanity_val_steps=0,\n",
        "    log_every_n_steps=10,\n",
        "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./final_log/\"),\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=pl_model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=val_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BghPUkwfxXdy"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j94rxuU0xXdy"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir final_log/lightning_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bsHtPzAxXdy"
      },
      "source": [
        "##  Оцените точность\n",
        "\n",
        "Оцените точность своей модели на `test_set`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4b2I0plxXdz"
      },
      "outputs": [],
      "source": [
        "trainer.test(model=pl_model, dataloaders=[test_loader])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh6A767RxXdz"
      },
      "source": [
        "# Задание 2. Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa3bGD8jxXdz"
      },
      "source": [
        "Теперь используйте технику `transfer learning` и дообучите предобученную сеть `efficientnet_lite0.ra_in1k`.\n",
        "\n",
        "* Загрузите предобученную сеть\n",
        "* Заморозьте параметры и обучите новый слой. Оцените качество на тесте\n",
        "* Разморозьте параметры и поучите уже всю сеть. Оцените качество на тесте"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR0KK25KxXdz"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "\n",
        "* Значение метрики на тестовом датасете\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCseAuJaxXdz"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "\n",
        "model = timm.create_model(\n",
        "    \"efficientnet_lite0.ra_in1k\", pretrained=True, num_classes=10, in_chans=13\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZuHMXA0xXdz"
      },
      "outputs": [],
      "source": [
        "for param in list(model.named_parameters())[:-2]:\n",
        "    param[1].requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP6AV1H6xXdz"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, \"\\t\", param[1].requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3ySc8J7xXdz"
      },
      "outputs": [],
      "source": [
        "pl_model = LModel(model)\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=10,\n",
        "    num_sanity_val_steps=0,\n",
        "    log_every_n_steps=10,\n",
        "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./final_log/\"),\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=pl_model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=val_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuLZwsVGxXdz"
      },
      "outputs": [],
      "source": [
        "trainer.test(model=pl_model, dataloaders=[test_loader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FczY3rXtxXdz"
      },
      "outputs": [],
      "source": [
        "for param in list(model.named_parameters()):\n",
        "    param[1].requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgCDnsq1xXdz"
      },
      "outputs": [],
      "source": [
        "pl_model = LModel(model)\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=3,\n",
        "    num_sanity_val_steps=0,\n",
        "    log_every_n_steps=10,\n",
        "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./final_log/\"),\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=pl_model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=val_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ks351pUxXdz"
      },
      "outputs": [],
      "source": [
        "trainer.test(model=pl_model, dataloaders=[test_loader])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSHe4Y_mxXd0"
      },
      "source": [
        "\n",
        "\n",
        "# Задание 3. Регрессия\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7LjexylxXd0"
      },
      "source": [
        "В этом задании вам нужно предсказать возраст человека по его фотографии."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ksdLA_xXd0"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "\n",
        "* Значение метрики на тестовом датасете\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jooTof5FxXd0"
      },
      "source": [
        "Датасет: http://yanweifu.github.io/FG_NET_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkPLzs7rxXd0"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/fg_net_data\n",
        "!wget -nc  http://yanweifu.github.io/FG_NET_data/FGNET.zip\n",
        "!unzip -q FGNET.zip -d /content/fg_net_data\n",
        "!rm FGNET.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rusmw_MoxXd0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "annotation = []\n",
        "img_paths = Path('/content/fg_net_data/FGNET/images').glob('**/*.JPG')\n",
        "for item in img_paths:\n",
        "    row = {}\n",
        "    row['img_path'] = item\n",
        "    row['age'] = np.float32(str(item).split('/')[-1][4:6])\n",
        "    annotation.append(row)\n",
        "annotation = pd.DataFrame(annotation)\n",
        "annotation.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKI98ZsnxXd0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5pBQKmuxXd0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train, x, y_train, y = train_test_split(\n",
        "    annotation['img_path'], annotation['age'], test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x, y, test_size=0.4, random_state=42\n",
        ")\n",
        "print('train shape: ', x_train.shape)\n",
        "print('val shape: ', x_val.shape)\n",
        "print('test shape: ', x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OufCgVExXd0"
      },
      "outputs": [],
      "source": [
        "annotation.age.hist()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMg7QE0YxXd0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "annotation['age_transformed'] = np.log1p(annotation.age.values)\n",
        "annotation.age_transformed.hist()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN_nGBMgxXd0"
      },
      "outputs": [],
      "source": [
        "annotation.iloc[x_train.index].to_csv('train_fg_net.csv', index=False)\n",
        "annotation.iloc[x_val.index].to_csv('val_fg_net.csv', index=False)\n",
        "annotation.iloc[x_test.index].to_csv('test_fg_net.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FHHS__DxXd0"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/train_fg_net.csv')\n",
        "val_data = pd.read_csv('/content/val_fg_net.csv')\n",
        "test_data = pd.read_csv('/content/test_fg_net.csv')\n",
        "\n",
        "train_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_EUw-2HxXd1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_data['age_transformed'].values.reshape(-1, 1))\n",
        "\n",
        "train_data['age_scaled'] = scaler.transform(train_data['age_transformed'].values.reshape(-1, 1))\n",
        "val_data['age_scaled'] = scaler.transform(val_data['age_transformed'].values.reshape(-1, 1))\n",
        "test_data['age_scaled'] = scaler.transform(test_data['age_transformed'].values.reshape(-1, 1))\n",
        "\n",
        "train_data.to_csv('train_fg_net.csv', index=False)\n",
        "val_data.to_csv('val_fg_net.csv', index=False)\n",
        "test_data.to_csv('test_fg_net.csv', index=False)\n",
        "\n",
        "train_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yiUYeERxXd1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        annotations_csv,\n",
        "        transforms=None,\n",
        "        target='age', # age/age_transformed/age_scaled\n",
        "    ):\n",
        "        self.annotation = pd.read_csv(annotations_csv)\n",
        "        self.transforms = transforms\n",
        "        self.target = target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotation)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.annotation.loc[idx, 'img_path'])\n",
        "        age = self.annotation.loc[idx, self.target]\n",
        "\n",
        "        # 1-channel to 3-channel\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        age = torch.as_tensor(age).float()\n",
        "        return image, age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19dim2lqxXd1"
      },
      "outputs": [],
      "source": [
        "train_set = CustomImageDataset('/content/train_fg_net.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGP5oF9bxXd1"
      },
      "outputs": [],
      "source": [
        "print(\"Image count: \", len(train_set))\n",
        "image, label = train_set[3]\n",
        "print(\"Type: \", type(image),\n",
        "      \"\\nsSize\", image.size,\n",
        "      \"\\nAge\", label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjs--Es3xXd1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
        "\n",
        "def show(img, label_1, num, label_2=\"\"):\n",
        "    ax = plt.subplot(1, 6, num + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Age: \"+str(label_1))\n",
        "    ax.set_xlabel(label_2)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "\n",
        "for i in range(6, 12):\n",
        "    img, label = train_set[i * 6]\n",
        "    show(img, int(label.item()), i - 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wwLDHjgxXd1"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "mean_on_img = torch.stack(\n",
        "    [torch.as_tensor(np.asarray(train_set[idx][0]).mean(axis=(0, 1))) for idx in tqdm(range(len(train_set)))]\n",
        ")\n",
        "mean_squared_on_img = torch.pow(mean_on_img, 2)\n",
        "squared_mean = mean_squared_on_img.mean(axis=0)\n",
        "\n",
        "mean_1 = mean_on_img.mean(axis=0)\n",
        "std_1 = np.sqrt(squared_mean - mean_1**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RPxXW4JxXd1"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)), # LongestMaxSize and PadIfNeeded\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_1, std_1),\n",
        "])\n",
        "\n",
        "train_set = CustomImageDataset('/content/train_fg_net.csv', transforms=img_transforms, target='age_scaled')\n",
        "val_set = CustomImageDataset('/content/val_fg_net.csv', transforms=img_transforms, target='age_scaled')\n",
        "test_set = CustomImageDataset('/content/test_fg_net.csv', transforms=img_transforms, target='age_scaled')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roKFKukVxXd1"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MHTXzsGxXd1"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.regression import MeanSquaredError\n",
        "\n",
        "\n",
        "class LModel(L.LightningModule):\n",
        "    def __init__(self, model, lr=0.001, gamma=0.9, scaler=None):\n",
        "        super().__init__()\n",
        "        self.scaler = scaler\n",
        "        self.save_hyperparameters(logger=False)\n",
        "\n",
        "        # for optimizer and shaduler\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # model\n",
        "        self.model = model\n",
        "        self.criterion = nn.HuberLoss() #nn.MSELoss()\n",
        "\n",
        "        # metrics\n",
        "        self.metrics = MetricCollection([\n",
        "            MeanSquaredError(squared=False),\n",
        "        ])\n",
        "        self.train_metrics = self.metrics.clone(postfix='/train')\n",
        "        self.val_metrics = self.metrics.clone(postfix='/val')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # set optimizer\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.lr,\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"interval\": \"epoch\",  # or 'step'\n",
        "                \"monitor\": \"loss\" # only for self.log\n",
        "            },\n",
        "        }\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y.unsqueeze(1))\n",
        "        self.train_metrics.update(out, y.unsqueeze(1))\n",
        "        self.log(\"loss\", loss, prog_bar=True, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        self.val_metrics.update(out, y.unsqueeze(1))\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log_dict(self.train_metrics.compute())\n",
        "        self.train_metrics.reset()\n",
        "\n",
        "        self.log_dict(self.val_metrics.compute())\n",
        "        self.val_metrics.reset()\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        if scaler:\n",
        "            y = self.scaler.inverse_transform(y.cpu().numpy().reshape(-1, 1))\n",
        "            out = self.scaler.inverse_transform(out.cpu().numpy().reshape(-1, 1))\n",
        "            y, out = torch.as_tensor(y).reshape(-1, 1).to(self.device), torch.as_tensor(out).reshape(-1, 1).to(self.device)\n",
        "        self.metrics.update(out, y)\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log_dict(self.metrics.compute())\n",
        "        self.metrics.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CijAAgBixXd1"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "L.seed_everything(42)\n",
        "\n",
        "\n",
        "model = timm.create_model(\n",
        "    \"tf_efficientnet_b0\", pretrained=True, num_classes=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NszHgkMUxXd2"
      },
      "outputs": [],
      "source": [
        "L.seed_everything(42)\n",
        "\n",
        "pl_model = LModel(model, scaler=scaler)\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=20,\n",
        "    log_every_n_steps=19,\n",
        "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./final_log/\"),\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=pl_model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=val_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8xmZAxaxXd2"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3Jv8reHxXd2"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir final_log/lightning_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_IRtWxxxXd2"
      },
      "outputs": [],
      "source": [
        "trainer.test(model=pl_model, dataloaders=[test_loader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqDxKeDoxXd2"
      },
      "outputs": [],
      "source": [
        "# get batch\n",
        "imgs, labels = next(iter(test_loader))\n",
        "print(\"imgs shape: \", imgs.shape)\n",
        "pred = model(imgs)\n",
        "print(\"pred shape: \", pred.shape)\n",
        "# inverse transform\n",
        "predict = scaler.inverse_transform(pred.cpu().detach().numpy().reshape(-1, 1))\n",
        "out = scaler.inverse_transform(labels.cpu().detach().numpy().reshape(-1, 1))\n",
        "\n",
        "predict = np.round(np.exp(predict)-1).reshape(1, -1)[0]\n",
        "out = np.round(np.exp(out)-1).reshape(1, -1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVj8j7n4xXd2"
      },
      "outputs": [],
      "source": [
        "def imshow(image):\n",
        "  npimg = image.numpy()\n",
        "  npimg = np.transpose(npimg, (1,2,0))\n",
        "  npimg = ((npimg * std_1.numpy()) + mean_1.numpy())\n",
        "  plt.imshow(npimg, interpolation='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSQ1e8cDxXd2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25.0, 25.0))\n",
        "for i in range(10):\n",
        "    img = imgs[i]\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.title(\n",
        "        \"pred: \" + str(int(predict[i])) + \" real: \" + str(int(out[i]))\n",
        "    )  # predicted and real values\n",
        "    imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QAML_4AxXd2"
      },
      "source": [
        "# Задание 4. CustomResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtBN78LQxXd2"
      },
      "source": [
        "Требуется самостоятельно реализовать свёрточную сеть на базе архитектуры ResNet-18, описанной в статье [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385).\n",
        "\n",
        "Создайте свою собственную сеть на основе архитектуры ResNet, описанной в лекции. От 15  до 25 слоев.\n",
        "\n",
        "Используйте заготовки классов `CustomResnet`, `BasicBlock`.\n",
        "\n",
        "Прежде чем приступать к работе, просмотрите оригинальную [статью](https://arxiv.org/pdf/1512.03385.pdf).\n",
        "\n",
        "*Не допускается целиком копировать код из исходников [PyTorch](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py).\n",
        "\n",
        "**Если вы используете готовый фрагмент кода, то должны быть приведены ссылка на источник и комментарии.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcOOpfpDxXd2"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "* Графики loss и accuracy при обучении\n",
        "\n",
        "<img src = \"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/Exercises/EX08/result_2_task_ex08.png\" width=\"1200\">\n",
        "\n",
        "* Значение accuracy на тесте должно составить не менее 0.77\n",
        "* Сравнительный анализ результатов точности вашей модели и библиотечной версии."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV6wHEUuxXd2"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Si9VRmgxXd2"
      },
      "outputs": [],
      "source": [
        "!pip install -q timm lightning torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjT2zuY-xXd2"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torchmetrics\n",
        "import torch.nn as nn\n",
        "import lightning as pl\n",
        "\n",
        "from torchsummary import summary\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Qc5ZT3xXd2"
      },
      "source": [
        "## Структура модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0AHWAhuxXd3"
      },
      "source": [
        "Прежде чем создавать собственную сеть, посмотрите архитектуру ResNet-18 из \"Зоопарка моделей\" PyTorch. Для этого используйте пакет [torchsummary](https://pypi.org/project/torch-summary/) или метод [add_graph](https://pytorch.org/docs/stable/tensorboard.html?highlight=add_graph#torch.utils.tensorboard.writer.SummaryWriter.add_graph) для TensorBoard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzjb0ZX2xXd3"
      },
      "source": [
        "Мы отказались от использования TB, и эталонное решение не должно использовать этот инструмент. Поэтому ограничимся torchsummary  :("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIZ56R6exXd3"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "from torchsummary import summary\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "resnet_original = resnet18()\n",
        "summary(resnet_original, (3, 32, 32), device=\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6cKrUJ9xXd3"
      },
      "source": [
        "Визуализировав библиотечную модель, можно заметить, что пространственные размеры тензора на выходе из последнего сверточного блока 7×7.\n",
        "\n",
        "Если подавать в такую сеть картинки, которые в 7 раз меньше (CIFAR-10 вместо ImageNet), то этот тензор схлопнется в вектор.\n",
        "\n",
        "Из этого можно сделать вывод о необходимости отключить слои, которые содержат свертки с большим шагом в начале сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5J0G8sPxXd3"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJszBctJxXd3"
      },
      "source": [
        "Блок кода, отвечающий за загрузку данных.\n",
        "Можно использовать без внесения изменений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAdh7H61xXd3"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data. Don't change this code\n",
        "\n",
        "# https://github.com/facebookarchive/fb.resnet.torch/issues/180\n",
        "cifar10_mean = (0.491, 0.482, 0.447)\n",
        "cifar10_std = (0.247, 0.244, 0.262)\n",
        "\n",
        "\n",
        "# Data preprocessing\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),  # PIL Image to Pytorch tensor [0..255]->[0 .. 1]\n",
        "        transforms.Normalize(\n",
        "            cifar10_mean, cifar10_std\n",
        "        ),  # https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transforms%20normalize#torchvision.transforms.Normalize\n",
        "    ]\n",
        ")\n",
        "\n",
        "cifar_train = datasets.CIFAR10(\n",
        "    \"content\", train=True, transform=transform, download=True\n",
        ")\n",
        "train_set, val_set = torch.utils.data.random_split(cifar_train, [45000, 5000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORNr_dZexXd3"
      },
      "source": [
        "Рекомендуется делать всю отладку на небольших фрагментах датасета, для чего создать объекты класса `Subset` и  соответствующие Dataloader-объекты.\n",
        "\n",
        "\n",
        "```\n",
        "mini_trainset , _ = torch.utils.data.random_split(trainset, [5000, 45000])\n",
        "mini_testset, _  = torch.utils.data.random_split(testset, [1000, 9000])\n",
        "...\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbeDbF8wxXd3"
      },
      "source": [
        "## Блок кода для обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3H5vh0rxXd3"
      },
      "source": [
        "В него можно вносить изменения, как минимум менять гиперпараметры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smo-NajFxXd3"
      },
      "outputs": [],
      "source": [
        "import lightning as pl\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class LightningModel(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.valid_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.model.parameters())\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        self.train_acc.update(out, y)\n",
        "        self.log(\"loss/train\", loss.detach().item())\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log(\"accuracy/train\", self.train_acc.compute(), prog_bar=True)\n",
        "        self.train_acc.reset()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        self.valid_acc.update(out, y)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log(\"accuracy/val\", self.valid_acc.compute(), prog_bar=True)\n",
        "        self.valid_acc.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5PV9l2SxXd3"
      },
      "source": [
        "## Основная часть задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbIWSeZbxXd3"
      },
      "source": [
        "Создайте свою собственную сеть на основе архитектуры ResNet, описанной в лекции. От 15  до 25 слоев.\n",
        "\n",
        "Используйте заготовки классов `CustomResnet`, `BasicBlock`.\n",
        "\n",
        "Прежде чем приступать к работе, просмотрите оригинальную [статью](https://arxiv.org/pdf/1512.03385.pdf).\n",
        "\n",
        "Не допускается копировать код из исходников [PyTorch](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py).\n",
        "\n",
        "Если вы используете готовый фрагмент кода, то должна быть приведена ссылка на источник и комментарии.\n",
        "\n",
        "Цель — добиться точности > 0.76.\n",
        "При разумной архитектуре и гиперпараметрах для этого достаточно 20 эпох."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARTzcFHmxXd3"
      },
      "outputs": [],
      "source": [
        "class CustomResnet(nn.Module):\n",
        "    def __init__(self, class_nums=10):\n",
        "        super(CustomResnet, self).__init__()\n",
        "        # Your code here\n",
        "        self.core = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            BasicBlock(16, False),\n",
        "            BasicBlock(16, True),  # 32x16x16\n",
        "            BasicBlock(32, False),\n",
        "            BasicBlock(32, True),  # 64x8x8\n",
        "            BasicBlock(64, False),\n",
        "            BasicBlock(64, False),  # 64x8x8\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "        return self.core(batch)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, downsample):  # You can add params here\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # Your code here\n",
        "        self.downsamlpe = downsample\n",
        "        if self.downsamlpe:\n",
        "            out_channels = in_channels * 2\n",
        "            stride = 2\n",
        "            # according to article option 2\n",
        "            self.downsample_layer = nn.Conv2d(\n",
        "                in_channels, out_channels, kernel_size=1, stride=2\n",
        "            )\n",
        "        else:\n",
        "            out_channels = in_channels\n",
        "            stride = 1\n",
        "            self.downsample_layer = None\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.Conv2d(\n",
        "                in_channels, out_channels, kernel_size=3, stride=stride, padding=1\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv(x)\n",
        "        if self.downsamlpe:\n",
        "            identity = self.downsample_layer(identity)\n",
        "        assert identity.shape == x.shape\n",
        "        return x + identity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNvjfWtExXd4"
      },
      "source": [
        "## Обучите вашу модель на CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kgN4aBtxXd4"
      },
      "source": [
        "Не забудьте вернуть в датасет данные, если вы удаляли их для ускорения отладки.\n",
        "\n",
        "Оптимизатор, количество эпох, шаг обучения, критерий останова выберите на свое усмотрение.\n",
        "\n",
        "Цель — добиться точности, лучшей, чем в прошлом задании."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmBz-XN8xXd4"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=128, num_workers=2, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=128, num_workers=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIf4D-_AxXd4"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "\n",
        "model = CustomResnet()\n",
        "lit_model = LightningModel(model)\n",
        "trainer = pl.Trainer(max_epochs=20)\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMWgFDxDxXd4"
      },
      "source": [
        "Проверьте качество на тестовой части датасета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2ga2IrSxXd4"
      },
      "outputs": [],
      "source": [
        "cifar_test = datasets.CIFAR10(\n",
        "    \"content\", train=False, transform=transform, download=True\n",
        ")\n",
        "test_loader = DataLoader(cifar_test, batch_size=256, shuffle=False)\n",
        "\n",
        "test_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "for batch in test_loader:\n",
        "    x, y = batch\n",
        "    out = lit_model.model(x)\n",
        "    test_metric.update(out, y)\n",
        "\n",
        "print(f\"Accuracy on TEST {test_metric.compute().item():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4heEX1mNxXd4"
      },
      "source": [
        "## Обучите ResNet-18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VgUE7dxXd4"
      },
      "source": [
        "Теперь обучите ResNet-18  из `torchvision.models` на том же CIFAR-10.\n",
        "Используйте непредобученную модель (`weights = None`)\n",
        "\n",
        "Для обучения на CIFAR-10 потребуется изменить параметры линейного слоя на выходе модели, так как в этом датасете 10 классов, а не 1000, как в ImageNet.\n",
        "\n",
        "Пример того, как можно подменить слой, можно найти [здесь](https://github.com/Gan4x4/CV-HSE2019/blob/master/helloworld/Change_model_structure.ipynb)\n",
        "\n",
        "После завершения обучения сравните точность вашей модели с точностью ResNet-18  из `torchvision.models`, а также с точностью, полученной авторами статьи на CIFAR-10:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEhQbnZVxXd4"
      },
      "source": [
        "<img src = \"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/Exercises/EX08/resnet_accuracy.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10LFwQ7LxXd4"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18\n",
        "\n",
        "resnet_original = resnet18()\n",
        "print(resnet_original.fc)\n",
        "resnet_original.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "print(resnet_original.fc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwBZWownxXd4"
      },
      "source": [
        "Заменим последний слой, отвечающий за классификацию, линейным слоем с 10-ю выходами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q04IwD-TxXd4"
      },
      "outputs": [],
      "source": [
        "lit_model = LightningModel(resnet_original)\n",
        "trainer = pl.Trainer(max_epochs=10)\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWMRaG_GxXd5"
      },
      "source": [
        "Оценим точность библиотечной модели на test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2rWF3GYxXd5"
      },
      "outputs": [],
      "source": [
        "test_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "for batch in test_loader:\n",
        "    x, y = batch\n",
        "    out = resnet_original(x)\n",
        "    test_metric.update(out, y)\n",
        "\n",
        "print(f\"Accuracy on TEST {test_metric.compute().item():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwlcuWbUxXd5"
      },
      "source": [
        "## Вывод:\n",
        "\n",
        "Сравнительный анализ результатов точности вашей модели и библиотечной версии.\n",
        "\n",
        "...\n",
        "\n",
        "Так как библиотечная модель рассчитана на работу с большими картинками из ImageNet (224×224), вполне естественно, что она плохо работает на крошечных картинках из CIFAR-10, которые сильно сжимаются на первых слоях.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}